{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g_3sx9YWK-f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q --no-cache transformers datasets nltk sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iR5mDomEPOZN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\deshi\\anaconda3\\envs\\py39-torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from transformers import RobertaTokenizer, T5ForConditionalGeneration\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V3P6k2bPT_TO"
      },
      "outputs": [],
      "source": [
        "def calculateSmoothedBLEU(reference, candidate):\n",
        "    \"\"\"\n",
        "    Calculate the Smoothed BLEU-4 score between a reference string and a candidate string.\n",
        "\n",
        "    Args:\n",
        "    reference (str): The reference (ground truth) string.\n",
        "    candidate (str): The candidate (generated) string.\n",
        "\n",
        "    Returns:\n",
        "    float: The Smoothed BLEU-4 score.\n",
        "    \"\"\"\n",
        "    reference_tokens = reference.split()\n",
        "    candidate_tokens = candidate.split()\n",
        "\n",
        "    smoother = SmoothingFunction()\n",
        "    bleu_score = sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=smoother.method1)\n",
        "\n",
        "    return bleu_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PL6a3X6aRWbd",
        "outputId": "ed2a01ca-5412-457e-ef77-84c9b93aeb30"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading builder script: 100%|██████████| 8.44k/8.44k [00:00<?, ?B/s]\n",
            "Downloading metadata: 100%|██████████| 18.5k/18.5k [00:00<?, ?B/s]\n",
            "Downloading readme: 100%|██████████| 12.9k/12.9k [00:00<?, ?B/s]\n",
            "Downloading data: 100%|██████████| 941M/941M [10:14<00:00, 1.53MB/s]\n",
            "Downloading data files: 100%|██████████| 1/1 [10:18<00:00, 618.09s/it]\n",
            "Extracting data files: 100%|██████████| 1/1 [00:13<00:00, 13.40s/it]\n",
            "Extracting data files: 100%|██████████| 3/3 [00:05<00:00,  1.79s/it]\n",
            "Generating train split: 100%|██████████| 412178/412178 [02:41<00:00, 2554.40 examples/s]\n",
            "Generating test split: 100%|██████████| 22176/22176 [00:08<00:00, 2623.99 examples/s]\n",
            "Generating validation split: 100%|██████████| 23107/23107 [00:10<00:00, 2126.07 examples/s]\n",
            "c:\\Users\\deshi\\anaconda3\\envs\\py39-torch\\lib\\site-packages\\datasets\\table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
            "  table = cls._concat_blocks(blocks, axis=0)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
              "    num_rows: 22176\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = load_dataset(\"code_search_net\", \"python\")['test']\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dmiPOLEkcr6Q"
      },
      "outputs": [],
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base-multi-sum')\n",
        "model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-base-multi-sum')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCBWWic_TP91",
        "outputId": "1c072c4a-7499-40a9-b79a-728a4d09bc53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text:\n",
            "def download_by_id(self, vid = '', title = None, output_dir='.', merge=True, info_only=False,**kwargs):\n",
            "        \"\"\"self, str->None\n",
            "        \n",
            "        Keyword arguments:\n",
            "        self: self\n",
            "        vid: The video ID for BokeCC cloud, something like\n",
            "        FE3BB999594978049C33DC5901307461\n",
            "        \n",
            "        Calls the prepare() to download the video.\n",
            "        \n",
            "        If no title is provided, this method shall try to find a proper title\n",
            "        with the information providin within the\n",
            "        returned content of the API.\"\"\"\n",
            "\n",
            "        assert vid\n",
            "\n",
            "        self.prepare(vid = vid, title = title, **kwargs)\n",
            "\n",
            "        self.extract(**kwargs)\n",
            "\n",
            "        self.download(output_dir = output_dir, \n",
            "                    merge = merge, \n",
            "                    info_only = info_only, **kwargs)\n",
            "\n",
            "Label:\n",
            "self, str->None\n",
            "        \n",
            "        Keyword arguments:\n",
            "        self: self\n",
            "        vid: The video ID for BokeCC cloud, something like\n",
            "        FE3BB999594978049C33DC5901307461\n",
            "        \n",
            "        Calls the prepare() to download the video.\n",
            "        \n",
            "        If no title is provided, this method shall try to find a proper title\n",
            "        with the information providin within the\n",
            "        returned content of the API.\n"
          ]
        }
      ],
      "source": [
        "idx = 14\n",
        "\n",
        "text = data['func_code_string'][idx]\n",
        "label = data['func_documentation_string'][idx]\n",
        "\n",
        "print(f'Text:\\n{text}\\n\\nLabel:\\n{label}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "J5ybnyusRPTt"
      },
      "outputs": [],
      "source": [
        "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
        "generated_ids = model.generate(input_ids, max_length=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MCghqAA_RQrv",
        "outputId": "b831bce5-7cc6-4710-9323-726d2fb493ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Download a single entry from the BokeCC cloud by ID.'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3IPg-0qVg2-",
        "outputId": "ef834c9a-dde5-4772-833d-18327da66834"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0006213748171322087\n"
          ]
        }
      ],
      "source": [
        "print(calculateSmoothedBLEU(label, predicted))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
