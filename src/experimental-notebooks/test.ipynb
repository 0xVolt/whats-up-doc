{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "g_3sx9YWK-f5"
      },
      "outputs": [],
      "source": [
        "%pip install -q --no-cache transformers datasets nltk sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer, T5ForConditionalGeneration\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "iR5mDomEPOZN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateSmoothedBLEU(reference, candidate):\n",
        "    \"\"\"\n",
        "    Calculate the Smoothed BLEU-4 score between a reference string and a candidate string.\n",
        "\n",
        "    Args:\n",
        "    reference (str): The reference (ground truth) string.\n",
        "    candidate (str): The candidate (generated) string.\n",
        "\n",
        "    Returns:\n",
        "    float: The Smoothed BLEU-4 score.\n",
        "    \"\"\"\n",
        "    reference_tokens = reference.split()\n",
        "    candidate_tokens = candidate.split()\n",
        "\n",
        "    smoother = SmoothingFunction()\n",
        "    bleu_score = sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=smoother.method1)\n",
        "\n",
        "    return bleu_score"
      ],
      "metadata": {
        "id": "V3P6k2bPT_TO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_dataset(\"code_search_net\", \"python\")['test']\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PL6a3X6aRWbd",
        "outputId": "ed2a01ca-5412-457e-ef77-84c9b93aeb30"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
              "    num_rows: 22176\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base-multi-sum')\n",
        "model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-base-multi-sum')"
      ],
      "metadata": {
        "id": "dmiPOLEkcr6Q"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 14\n",
        "\n",
        "text = data['func_code_string'][idx]\n",
        "label = data['func_documentation_string'][idx]\n",
        "\n",
        "print(f'Text:\\n{text}\\n\\nLabel:\\n{label}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCBWWic_TP91",
        "outputId": "1c072c4a-7499-40a9-b79a-728a4d09bc53"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:\n",
            "def download_by_id(self, vid = '', title = None, output_dir='.', merge=True, info_only=False,**kwargs):\n",
            "        \"\"\"self, str->None\n",
            "        \n",
            "        Keyword arguments:\n",
            "        self: self\n",
            "        vid: The video ID for BokeCC cloud, something like\n",
            "        FE3BB999594978049C33DC5901307461\n",
            "        \n",
            "        Calls the prepare() to download the video.\n",
            "        \n",
            "        If no title is provided, this method shall try to find a proper title\n",
            "        with the information providin within the\n",
            "        returned content of the API.\"\"\"\n",
            "\n",
            "        assert vid\n",
            "\n",
            "        self.prepare(vid = vid, title = title, **kwargs)\n",
            "\n",
            "        self.extract(**kwargs)\n",
            "\n",
            "        self.download(output_dir = output_dir, \n",
            "                    merge = merge, \n",
            "                    info_only = info_only, **kwargs)\n",
            "\n",
            "Label:\n",
            "self, str->None\n",
            "        \n",
            "        Keyword arguments:\n",
            "        self: self\n",
            "        vid: The video ID for BokeCC cloud, something like\n",
            "        FE3BB999594978049C33DC5901307461\n",
            "        \n",
            "        Calls the prepare() to download the video.\n",
            "        \n",
            "        If no title is provided, this method shall try to find a proper title\n",
            "        with the information providin within the\n",
            "        returned content of the API.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
        "generated_ids = model.generate(input_ids, max_length=20)"
      ],
      "metadata": {
        "id": "J5ybnyusRPTt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MCghqAA_RQrv",
        "outputId": "b831bce5-7cc6-4710-9323-726d2fb493ae"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Download a single entry from the BokeCC cloud by ID.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(calculateSmoothedBLEU(label, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3IPg-0qVg2-",
        "outputId": "ef834c9a-dde5-4772-833d-18327da66834"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0006213748171322087\n"
          ]
        }
      ]
    }
  ]
}