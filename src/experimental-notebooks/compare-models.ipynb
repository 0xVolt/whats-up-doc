{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0xVolt/whats-up-doc/blob/main/src/experimental-notebooks/compare-models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UED-fV4iG5iu"
      },
      "source": [
        "# Compare Various HuggingFace Models for CDG by `SmoothedBLEU` Score\n",
        "\n",
        "## Purpose\n",
        "\n",
        "The purpose of this notebook is to figure out which models will work best for our CLI app. We will calculate and compare these select models by their smoothed BLEU scores and possibly look into fine-tuning them with [this dataset](https://www.dropbox.com/sh/488bq2of10r4wvw/AACs5CGIQuwtsD7j_Ls_JAORa/finetuning_dataset?dl=0&subfolder_nav_tracking=1).\n",
        "\n",
        "## Models\n",
        "\n",
        "These are the models we'll create inference points for and load in this notebook.\n",
        "1. [SEBIS/code_trans_t5_base_code_documentation_generation_python](https://huggingface.co/SEBIS/code_trans_t5_base_code_documentation_generation_python)\n",
        "2. [Salesforce/codet5-base-multi-sum](https://huggingface.co/Salesforce/codet5-base-multi-sum)\n",
        "3. [google/flan-t5-small](https://huggingface.co/google/flan-t5-small)\n",
        "\n",
        "The models listed above have been fine-tuned on the CodeSearchNet dataset across various programming languages for PL-NL sequence-to-sequence tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8E79z95HYnR"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wJbpYXdGluQ",
        "outputId": "9f9a1b40-ff83-4431-98d3-05fbc0927d70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q transformers sentencepiece datasets nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelWithLMHead, RobertaTokenizer, T5Tokenizer, T5ForConditionalGeneration, SummarizationPipeline\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from datasets import load_dataset\n",
        "import tokenize\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Evaluation Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KjjG2VfSHXpA"
      },
      "outputs": [],
      "source": [
        "def calculateSmoothedBLEU(reference, candidate):\n",
        "    \"\"\"\n",
        "    Calculate the Smoothed BLEU-4 score between a reference string and a candidate string.\n",
        "\n",
        "    Args:\n",
        "    reference (str): The reference (ground truth) string.\n",
        "    candidate (str): The candidate (generated) string.\n",
        "\n",
        "    Returns:\n",
        "    float: The Smoothed BLEU-4 score.\n",
        "    \"\"\"\n",
        "    reference_tokens = reference.split()\n",
        "    candidate_tokens = candidate.split()\n",
        "\n",
        "    smoother = SmoothingFunction()\n",
        "    bleu_score = sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=smoother.method1)\n",
        "\n",
        "    return bleu_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Python Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pythonTokenizer(line):\n",
        "    result = []\n",
        "    line = io.StringIO(line)\n",
        "\n",
        "    for tokenType, token, start, end, line in tokenize.generate_tokens(line.readline):\n",
        "        if (not tokenType == tokenize.COMMENT):\n",
        "            if tokenType == tokenize.STRING:\n",
        "                result.append(\"CODE_STRING\")\n",
        "            elif tokenType == tokenize.NUMBER:\n",
        "                result.append(\"CODE_INTEGER\")\n",
        "            elif (not token == \"\\n\") and (not token == \"    \"):\n",
        "                result.append(str(token))\n",
        "                \n",
        "    return ' '.join(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CodeTransT5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "codeTransModel = AutoModelWithLMHead.from_pretrained(\"SEBIS/code_trans_t5_base_source_code_summarization_python_transfer_learning_finetune\")\n",
        "codeTransTokenizer = AutoTokenizer.from_pretrained(\"SEBIS/code_trans_t5_base_source_code_summarization_python_transfer_learning_finetune\", skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CodeT5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading pytorch_model.bin: 100%|██████████| 892M/892M [08:04<00:00, 1.84MB/s]\n",
            "Downloading (…)okenizer_config.json: 100%|██████████| 1.48k/1.48k [00:00<00:00, 370kB/s]\n",
            "Downloading (…)olve/main/vocab.json: 100%|██████████| 703k/703k [00:00<00:00, 734kB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100%|██████████| 294k/294k [00:00<00:00, 7.74MB/s]\n",
            "Downloading (…)in/added_tokens.json: 100%|██████████| 2.00/2.00 [00:00<00:00, 508B/s]\n",
            "Downloading (…)cial_tokens_map.json: 100%|██████████| 12.5k/12.5k [00:00<00:00, 1.92MB/s]\n"
          ]
        }
      ],
      "source": [
        "codeT5Model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-base-multi-sum')\n",
        "codeT5Tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base-multi-sum', skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### FlanT5 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading (…)lve/main/config.json: 100%|██████████| 1.40k/1.40k [00:00<00:00, 432kB/s]\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\deshi\\Code\\whats-up-doc\\src\\experimental-notebooks\\compare-models.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/deshi/Code/whats-up-doc/src/experimental-notebooks/compare-models.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m flanT5Model \u001b[39m=\u001b[39m T5ForConditionalGeneration\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mgoogle/flan-t5-small\u001b[39;49m\u001b[39m\"\u001b[39;49m, device_map\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/deshi/Code/whats-up-doc/src/experimental-notebooks/compare-models.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m flanT5Tokenizer \u001b[39m=\u001b[39m T5Tokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mgoogle/flan-t5-small\u001b[39m\u001b[39m\"\u001b[39m, skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\deshi\\anaconda3\\envs\\py39-torch\\lib\\site-packages\\transformers\\modeling_utils.py:2674\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2670\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2671\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mDeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2672\u001b[0m         )\n\u001b[0;32m   2673\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_accelerate_available():\n\u001b[1;32m-> 2674\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m   2675\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2676\u001b[0m         )\n\u001b[0;32m   2678\u001b[0m quantization_method_from_args \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2679\u001b[0m \u001b[39mif\u001b[39;00m quantization_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mImportError\u001b[0m: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`"
          ]
        }
      ],
      "source": [
        "flanT5Model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\", device_map=\"auto\")\n",
        "flanT5Tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\", skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "codeTransPipeline = SummarizationPipeline(\n",
        "    model=codeTransModel,\n",
        "    tokenizer=codeTransTokenizer,\n",
        "    device=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "codeT5Pipeline = SummarizationPipeline(\n",
        "    model=codeT5Model,\n",
        "    tokenizer=codeT5Tokenizer,\n",
        "    device=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flanPipeline = SummarizationPipeline(\n",
        "    model=flanT5Model,\n",
        "    tokenizer=flanT5Tokenizer,\n",
        "    device=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "code = '''\n",
        "\n",
        "def is_prime(number):\n",
        "    if number <= 1:\n",
        "        return False\n",
        "    elif number <= 3:\n",
        "        return True\n",
        "    elif number % 2 == 0 or number % 3 == 0:\n",
        "        return False\n",
        "    i = 5\n",
        "    while i * i <= number:\n",
        "        if number % i == 0 or number % (i + 2) == 0:\n",
        "            return False\n",
        "        i += 6\n",
        "    return True\n",
        "        \n",
        "''' #@param {type:\"raw\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = {\n",
        "    codeTrans: {\n",
        "        output: str(codeTransPipeline([tokenizedCode])[0])\n",
        "    }\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPTWE3sLB2iBAUp0BOuv8y3",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
