{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/transformers.git -q -U # transformers version:  4.37.0\n!pip install git+https://github.com/huggingface/accelerate.git -q -U # accelerate version:  0.27.0\n!pip install bitsandbytes # bitsandbytes version:  0.42.0\n!pip install git+https://github.com/huggingface/peft.git -q -U # peft version: 0.7.2\n!pip install torch\n!pip install --upgrade bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-05-26T06:43:45.460411Z","iopub.execute_input":"2024-05-26T06:43:45.461220Z","iopub.status.idle":"2024-05-26T06:46:15.393237Z","shell.execute_reply.started":"2024-05-26T06:43:45.461187Z","shell.execute_reply":"2024-05-26T06:46:15.392169Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.1\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.43.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login as hfl\nfrom transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-05-26T06:46:15.395162Z","iopub.execute_input":"2024-05-26T06:46:15.395465Z","iopub.status.idle":"2024-05-26T06:46:30.214944Z","shell.execute_reply.started":"2024-05-26T06:46:15.395437Z","shell.execute_reply":"2024-05-26T06:46:30.214005Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-05-26 06:46:19.248001: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-26 06:46:19.248098: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-26 06:46:19.371724: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"hfl()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T06:46:30.216246Z","iopub.execute_input":"2024-05-26T06:46:30.217099Z","iopub.status.idle":"2024-05-26T06:46:30.242962Z","shell.execute_reply.started":"2024-05-26T06:46:30.217057Z","shell.execute_reply":"2024-05-26T06:46:30.242135Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef5b28149180426eb2681e45e31f50d8"}},"metadata":{}}]},{"cell_type":"code","source":"model_id = \"0xVolt/Meta-Llama-3-8B-Instruct-Hermes-2-Pro-SLERP\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T06:48:03.239848Z","iopub.execute_input":"2024-05-26T06:48:03.240592Z","iopub.status.idle":"2024-05-26T06:48:07.720365Z","shell.execute_reply.started":"2024-05-26T06:48:03.240560Z","shell.execute_reply":"2024-05-26T06:48:07.719549Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e09fefa3e6524a999361048375f883dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03b63577e5ac4a87a62d628bc8855ede"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa1eac7409424f2eb949e17406cdb5a5"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n        model_id,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n        trust_remote_code=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T06:49:38.929685Z","iopub.execute_input":"2024-05-26T06:49:38.930296Z","iopub.status.idle":"2024-05-26T07:02:38.617705Z","shell.execute_reply.started":"2024-05-26T06:49:38.930266Z","shell.execute_reply":"2024-05-26T07:02:38.616964Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/707 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22a053e8b9f241329d258318becefee8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/22.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14849637811942e188428b671d19debc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/17 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a117e0aa1bd479992baa25623cf0127"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00017.safetensors:   0%|          | 0.00/1.05G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44c0555853ce4c1e9b88be0ff724033a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00017.safetensors:   0%|          | 0.00/1.05G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71f63e124fd44a58bdd697b12e299e40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00017.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98aaa3a1bb90464d9e3596d659066b62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00017.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17f6a99e5759477dae1e35da5e01a15d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00017.safetensors:   0%|          | 0.00/998M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"922006f5b81c4413999b4ac6532484f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00017.safetensors:   0%|          | 0.00/948M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9da6d4e2716847d6ab215d383ddb11da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00007-of-00017.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b266ae61e7d4bd4a234c068d1dbc261"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00008-of-00017.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58f4bfd213cf45018527ffa196d74322"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00009-of-00017.safetensors:   0%|          | 0.00/998M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bac7dcd9acdf41a8953ce40c284359d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00010-of-00017.safetensors:   0%|          | 0.00/948M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba74f29437e44dd0839fe56938c53334"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00011-of-00017.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6dbf7d541754fe5b0f514fdf0a3e9e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00012-of-00017.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1565384d28af47a58d96a3c8cb8250aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00013-of-00017.safetensors:   0%|          | 0.00/998M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55e3d1548c174c72a688d61f2e678613"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00014-of-00017.safetensors:   0%|          | 0.00/948M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"608a19a209fb431ca29cd6580c7464ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00015-of-00017.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75d29d87e96c4af5a70e048ca543d7b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00016-of-00017.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57786a56f1e7433a93ac1c2d385df5fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00017-of-00017.safetensors:   0%|          | 0.00/201M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ff123e84a444a1c8d6a31b7d5b8b0bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2e68ce9e6514ebeae9e036a00e527d4"}},"metadata":{}}]},{"cell_type":"code","source":"example = {\n    \"instruction\": \"Write a function that implements post-order traversal for an input binary tree as a dictionary or map in Python.\"\n}\n\ndef formatPromptFromDictionary(example):\n    prompt = f\"<s>[INST]Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.{example['instruction']}[/INST]\"\n    \n    return prompt\n\nexamplePrompt = formatPromptFromDictionary(example)\nprint(f'Prompt Template:\\n{examplePrompt}')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-26T07:05:43.728129Z","iopub.execute_input":"2024-05-26T07:05:43.728510Z","iopub.status.idle":"2024-05-26T07:05:43.734287Z","shell.execute_reply.started":"2024-05-26T07:05:43.728482Z","shell.execute_reply":"2024-05-26T07:05:43.733346Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Prompt Template:\n<s>[INST]Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.Write a function that implements post-order traversal for an input binary tree as a dictionary or map in Python.[/INST]\n","output_type":"stream"}]},{"cell_type":"code","source":"from datetime import datetime\nimport re\n\ndef model_seq_gen(model, temp=0.7) : \n        pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer)\n        \n        start = datetime.now()\n        \n        sequences = pipe(\n            examplePrompt,\n            do_sample=True,\n            max_new_tokens=100, \n            temperature=temp, \n            top_k=50, \n            top_p=0.95,\n            num_return_sequences=1\n        )\n        \n        output = sequences[0]['generated_text'].split(\"[/INST]\")[1]\n        stop = datetime.now()\n        time_taken = stop-start\n        \n        print(f\"Execution Time: {time_taken}s\")\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2024-05-26T07:05:44.223430Z","iopub.execute_input":"2024-05-26T07:05:44.224060Z","iopub.status.idle":"2024-05-26T07:05:44.230482Z","shell.execute_reply.started":"2024-05-26T07:05:44.224022Z","shell.execute_reply":"2024-05-26T07:05:44.229607Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"output = model_seq_gen(model, 0.5)\ndisplay(output)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T07:05:45.929309Z","iopub.execute_input":"2024-05-26T07:05:45.929931Z","iopub.status.idle":"2024-05-26T07:06:47.950001Z","shell.execute_reply.started":"2024-05-26T07:05:45.929902Z","shell.execute_reply":"2024-05-26T07:06:47.949105Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Execution Time: 0:01:02.013244\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\"Here is the Python function that implements post-order traversal for a binary tree represented as a dictionary or map:\\n\\n```python\\ndef post_order_traversal(tree):\\n    result = []\\n    if tree:\\n        result.extend(post_order_traversal(tree.get('left')))\\n        result.extend(post_order_traversal(tree.get('right')))\\n        result.append(tree.get('value'))\\n    return result\\n```\\n\\nThis function takes a dictionary or map representing a binary tree as input. The tree is assumed to have a 'left\""},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}