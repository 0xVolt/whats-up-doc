{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","include_colab_link":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/0xVolt/whats-up-doc/blob/main/test/notebooks/model-blending/blend.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"colab_type":"text","id":"view-in-github"}},{"cell_type":"markdown","source":"# Merging CodeLLMs to Create an Efficant Low-Memory Quantized Model for `whats-up-doc` using the TIES Method\n\n## Download and Install `mergekit`","metadata":{"id":"dM0FHFhyY2g2"}},{"cell_type":"code","source":"import os\n\ndirName = \"mergekit\"\ncwd = os.getcwd()\n\nconcatDirPath = os.path.join(cwd, dirName)\n\nif not os.path.exists(concatDirPath):\n    !git clone https://github.com/cg123/mergekit.git\n    !cd mergekit && pip install -q -e .","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NPNPie5Eo3EZ","outputId":"b262d7b3-9f30-4725-a9db-7711af5ae836","execution":{"iopub.status.busy":"2024-05-19T11:19:00.141550Z","iopub.execute_input":"2024-05-19T11:19:00.141913Z","iopub.status.idle":"2024-05-19T11:19:44.492191Z","shell.execute_reply.started":"2024-05-19T11:19:00.141874Z","shell.execute_reply":"2024-05-19T11:19:44.491164Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'mergekit'...\nremote: Enumerating objects: 2265, done.\u001b[K\nremote: Counting objects: 100% (1340/1340), done.\u001b[K\nremote: Compressing objects: 100% (514/514), done.\u001b[K\nremote: Total 2265 (delta 1068), reused 939 (delta 825), pack-reused 925\u001b[K\nReceiving objects: 100% (2265/2265), 638.44 KiB | 16.80 MiB/s, done.\nResolving deltas: 100% (1584/1584), done.\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.9.3 requires keras-core, which is not installed.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.1.6 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"## Create the YAML Config File to Merge Models with SLERP","metadata":{"id":"rU1g6RzPKt5s"}},{"cell_type":"code","source":"import os\nimport yaml\nfrom transformers import AutoModelWithLMHead, AutoTokenizer, pipeline","metadata":{"id":"ezsCJA5DX9eQ","execution":{"iopub.status.busy":"2024-05-19T11:19:44.493992Z","iopub.execute_input":"2024-05-19T11:19:44.494303Z","iopub.status.idle":"2024-05-19T11:20:03.537952Z","shell.execute_reply.started":"2024-05-19T11:19:44.494273Z","shell.execute_reply":"2024-05-19T11:20:03.537180Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-05-19 11:19:52.194007: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-19 11:19:52.194105: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-19 11:19:52.335750: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"%pip install huggingface-cli","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RMb9YxyUUbaF","outputId":"b94ec400-b1c3-42cf-b392-b07516aaee43","execution":{"iopub.status.busy":"2024-05-19T11:20:03.539117Z","iopub.execute_input":"2024-05-19T11:20:03.539856Z","iopub.status.idle":"2024-05-19T11:20:15.930113Z","shell.execute_reply.started":"2024-05-19T11:20:03.539803Z","shell.execute_reply":"2024-05-19T11:20:15.928794Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting huggingface-cli\n  Downloading huggingface_cli-0.1-py3-none-any.whl.metadata (117 bytes)\nDownloading huggingface_cli-0.1-py3-none-any.whl (1.0 kB)\nInstalling collected packages: huggingface-cli\nSuccessfully installed huggingface-cli-0.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuserSecrets = UserSecretsClient()\nHF_WRITE_TOKEN = userSecrets.get_secret(\"HF_WRITE_TOKEN\")","metadata":{"execution":{"iopub.status.busy":"2024-05-19T11:20:15.933665Z","iopub.execute_input":"2024-05-19T11:20:15.934009Z","iopub.status.idle":"2024-05-19T11:20:16.104882Z","shell.execute_reply.started":"2024-05-19T11:20:15.933977Z","shell.execute_reply":"2024-05-19T11:20:16.104089Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Write Config Script","metadata":{"id":"VHwE6E7cLLOx"}},{"cell_type":"code","source":"# Set the resultant model's name\nMODEL_NAME = 'whats-up-llamas-ties'\n\nMODEL_1 = \"meta-llama/Meta-Llama-3-8B-Instruct\"\nMODEL_2 = \"codellama/CodeLlama-7b-Instruct-hf\"\n\nOUTPUT_DIR = \"whats-up-llamas-ties\"","metadata":{"id":"4zrN0st2U1_O","execution":{"iopub.status.busy":"2024-05-19T11:21:09.631393Z","iopub.execute_input":"2024-05-19T11:21:09.632406Z","iopub.status.idle":"2024-05-19T11:21:09.637245Z","shell.execute_reply.started":"2024-05-19T11:21:09.632369Z","shell.execute_reply":"2024-05-19T11:21:09.636371Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"#### TIES YAML Config Creation","metadata":{"id":"ltwEFfdUkqXG"}},{"cell_type":"code","source":"yamlConfigTIESLlamas = f\"\"\"\nmodels:\n  - model: {MODEL_1}  # no parameters necessary for base model\n  - model: {MODEL_2}\n    parameters:\n      density: 0.5\n      weight: 0.5\nmerge_method: ties\nbase_model: {MODEL_1}\nparameters:\n  normalize: true\n  int8_mask: true\ndtype: float16\n\n\"\"\"","metadata":{"id":"tOafmTvbkhM8","execution":{"iopub.status.busy":"2024-05-19T11:24:20.061296Z","iopub.execute_input":"2024-05-19T11:24:20.062067Z","iopub.status.idle":"2024-05-19T11:24:20.066452Z","shell.execute_reply.started":"2024-05-19T11:24:20.062034Z","shell.execute_reply":"2024-05-19T11:24:20.065535Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Save Config Script","metadata":{"id":"fT4cHC-9LPLO"}},{"cell_type":"code","source":"# Save the YAML configuration to a file\nyamlFileName = \"config.yaml\"\nwith open(yamlFileName, \"w\") as f:\n    f.write(yamlConfigTIESLlamas)","metadata":{"id":"mA1SMKrgQH39","execution":{"iopub.status.busy":"2024-05-19T11:24:30.771639Z","iopub.execute_input":"2024-05-19T11:24:30.772369Z","iopub.status.idle":"2024-05-19T11:24:30.777043Z","shell.execute_reply.started":"2024-05-19T11:24:30.772338Z","shell.execute_reply":"2024-05-19T11:24:30.776079Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Merge Models","metadata":{"id":"ked5Gn7NLXuw"}},{"cell_type":"code","source":"cmd = f\"mergekit-yaml {yamlFileName} {OUTPUT_DIR} --allow-crimes --copy-tokenizer --out-shard-size 1B --low-cpu-memory --write-model-card --lazy-unpickle\"\n!{cmd}","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o8XlZ9UmSfdS","outputId":"c1b1f3f9-a2ce-40e3-8eae-c5166e347587","execution":{"iopub.status.busy":"2024-05-19T11:24:59.250824Z","iopub.execute_input":"2024-05-19T11:24:59.251192Z","iopub.status.idle":"2024-05-19T11:25:06.333355Z","shell.execute_reply.started":"2024-05-19T11:24:59.251161Z","shell.execute_reply":"2024-05-19T11:25:06.332360Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\", line 304, in hf_raise_for_status\n    response.raise_for_status()\n  File \"/opt/conda/lib/python3.10/site-packages/requests/models.py\", line 1021, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py\", line 398, in cached_file\n    resolved_file = hf_hub_download(\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 119, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1403, in hf_hub_download\n    raise head_call_error\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1261, in hf_hub_download\n    metadata = get_hf_file_metadata(\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 119, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1674, in get_hf_file_metadata\n    r = _request_wrapper(\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 369, in _request_wrapper\n    response = _request_wrapper(\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 393, in _request_wrapper\n    hf_raise_for_status(response)\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\", line 321, in hf_raise_for_status\n    raise GatedRepoError(message, response) from e\nhuggingface_hub.utils._errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-6649e191-1da05d2c14b8cf216a2c417a;9d0acff6-f698-45cc-b01e-560184f0677f)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Meta-Llama-3-8B-Instruct is restricted. You must be authenticated to access it.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/conda/bin/mergekit-yaml\", line 8, in <module>\n    sys.exit(main())\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 1078, in main\n    rv = self.invoke(ctx)\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/kaggle/working/mergekit/mergekit/options.py\", line 82, in wrapper\n    f(*args, **kwargs)\n  File \"/kaggle/working/mergekit/mergekit/scripts/run_yaml.py\", line 47, in main\n    run_merge(\n  File \"/kaggle/working/mergekit/mergekit/merge.py\", line 46, in run_merge\n    model_arch_info = [\n  File \"/kaggle/working/mergekit/mergekit/merge.py\", line 47, in <listcomp>\n    get_architecture_info(m.config(trust_remote_code=options.trust_remote_code))\n  File \"/kaggle/working/mergekit/mergekit/common.py\", line 125, in config\n    res = AutoConfig.from_pretrained(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py\", line 1138, in from_pretrained\n    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py\", line 631, in get_config_dict\n    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py\", line 686, in _get_config_dict\n    resolved_config_file = cached_file(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py\", line 416, in cached_file\n    raise EnvironmentError(\nOSError: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct.\n401 Client Error. (Request ID: Root=1-6649e191-1da05d2c14b8cf216a2c417a;9d0acff6-f698-45cc-b01e-560184f0677f)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Meta-Llama-3-8B-Instruct is restricted. You must be authenticated to access it.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}