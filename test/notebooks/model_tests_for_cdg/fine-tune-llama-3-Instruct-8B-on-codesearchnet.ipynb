{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!mamba install --quiet --force-reinstall aiohttp -y\n!pip install -qU \"xformers<0.0.26\" --index-url https://download.pytorch.org/whl/cu121\n!pip install -q \"unsloth[kaggle-new] @ git+https://github.com/unslothai/unsloth.git\"\n# !pip install wandb evaluate accelerate\n\n# Temporary fix for https://github.com/huggingface/datasets/issues/6753\n!pip install datasets==2.16.0 fsspec==2023.10.0 gcsfs==2023.10.0\n\nimport os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-26T11:50:28.357053Z","iopub.execute_input":"2024-07-26T11:50:28.357931Z","iopub.status.idle":"2024-07-26T11:54:55.800978Z","shell.execute_reply.started":"2024-07-26T11:50:28.357891Z","shell.execute_reply":"2024-07-26T11:54:55.799907Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/c6f2354e.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/86b0f08d.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/c9ddbd6b.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/b121c3e7.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/497deca9.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/09cdf8bf.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/47929eba.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/3e39a7aa.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/2ce54b42.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/4ea078d6.json\" was modified by another program\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\n\u001b[33mWARNING: huggingface-hub 0.23.4 does not provide the extra 'hf-transfer'\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mCollecting datasets==2.16.0\n  Downloading datasets-2.16.0-py3-none-any.whl.metadata (20 kB)\nCollecting fsspec==2023.10.0\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nCollecting gcsfs==2023.10.0\n  Downloading gcsfs-2023.10.0-py2.py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (1.26.4)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (0.6)\nCollecting dill<0.3.8,>=0.3.0 (from datasets==2.16.0)\n  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (0.23.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (6.0.1)\nRequirement already satisfied: decorator>4.1.2 in /opt/conda/lib/python3.10/site-packages (from gcsfs==2023.10.0) (5.1.1)\nRequirement already satisfied: google-auth>=1.2 in /opt/conda/lib/python3.10/site-packages (from gcsfs==2023.10.0) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib in /opt/conda/lib/python3.10/site-packages (from gcsfs==2023.10.0) (1.2.0)\nRequirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (from gcsfs==2023.10.0) (1.44.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (4.0.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs==2023.10.0) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs==2023.10.0) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs==2023.10.0) (4.9)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets==2.16.0) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.16.0) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.16.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.16.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.16.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.16.0) (2024.7.4)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib->gcsfs==2023.10.0) (1.3.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs==2023.10.0) (1.16.0)\nRequirement already satisfied: google-api-core<3.0dev,>=1.29.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs==2023.10.0) (2.11.1)\nRequirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs==2023.10.0) (2.4.1)\nRequirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs==2023.10.0) (2.7.0)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs==2023.10.0) (3.20.3)\nINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\nCollecting multiprocess (from datasets==2.16.0)\n  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.0) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.0) (2023.4)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage->gcsfs==2023.10.0) (1.62.0)\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage->gcsfs==2023.10.0) (1.5.0)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs==2023.10.0) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs==2023.10.0) (3.2.2)\nDownloading datasets-2.16.0-py3-none-any.whl (507 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gcsfs-2023.10.0-py2.py3-none-any.whl (33 kB)\nDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, dill, multiprocess, datasets, gcsfs\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2024.5.0\n    Uninstalling fsspec-2024.5.0:\n      Successfully uninstalled fsspec-2024.5.0\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.16\n    Uninstalling multiprocess-0.70.16:\n      Successfully uninstalled multiprocess-0.70.16\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.20.0\n    Uninstalling datasets-2.20.0:\n      Successfully uninstalled datasets-2.20.0\n  Attempting uninstall: gcsfs\n    Found existing installation: gcsfs 2024.5.0\n    Uninstalling gcsfs-2024.5.0:\n      Successfully uninstalled gcsfs-2024.5.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.6.1 requires cubinlinker, which is not installed.\ncudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.6.1 requires ptxcompiler, which is not installed.\ncuml 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ncudf 24.6.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndistributed 2024.5.1 requires dask==2024.5.1, but you have dask 2024.7.0 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\nrapids-dask-dependency 24.6.0a0 requires dask==2024.5.1, but you have dask 2024.7.0 which is incompatible.\ns3fs 2024.5.0 requires fsspec==2024.5.0.*, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.16.0 dill-0.3.7 fsspec-2023.10.0 gcsfs-2023.10.0 multiprocess-0.70.15\n","output_type":"stream"}]},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nimport pprint as pp\nfrom datasets import load_dataset\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-07-26T11:54:55.802993Z","iopub.execute_input":"2024-07-26T11:54:55.803295Z","iopub.status.idle":"2024-07-26T11:55:14.339303Z","shell.execute_reply.started":"2024-07-26T11:54:55.803268Z","shell.execute_reply":"2024-07-26T11:55:14.338466Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2024-07-26 11:55:04.140453: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-26 11:55:04.140573: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-26 11:55:04.279614: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"max_seq_length = 2048\ndtype = None\nload_in_4bit = True\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-26T11:55:14.340460Z","iopub.execute_input":"2024-07-26T11:55:14.341077Z","iopub.status.idle":"2024-07-26T11:55:44.101615Z","shell.execute_reply.started":"2024-07-26T11:55:14.341047Z","shell.execute_reply":"2024-07-26T11:55:44.100865Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"==((====))==  Unsloth: Fast Llama patching release 2024.8\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\nO^O/ \\_/ \\    Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.25.post1. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bc18455af164357bec68ce53e246ad1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/131 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef43ea7769634eac893888db4c4a0c53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12b1b6d688cc418da4d797e59cb5e8f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da0c392f4db64f96ae72a3c297ddaac8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3627be4395f45b88721beea92c59d25"}},"metadata":{}}]},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 32,\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0,\n    bias = \"none\",\n    use_gradient_checkpointing = True, # Set to True if out of memory (default is \"unsloth\")\n    random_state = 3407,\n    use_rslora = False,\n    loftq_config = None,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-26T11:55:44.104131Z","iopub.execute_input":"2024-07-26T11:55:44.104845Z","iopub.status.idle":"2024-07-26T11:55:47.508797Z","shell.execute_reply.started":"2024-07-26T11:55:44.104809Z","shell.execute_reply":"2024-07-26T11:55:47.507957Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Unsloth 2024.8 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}]},{"cell_type":"code","source":"alpacaFormatString = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\n{}\n\n### Input:\n{}\n\n### Response:\n{}\"\"\"\n\nEOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN (<|eot_id|>)\n\n# Define the formatting function to initially drop all the unnecessary columns and rename what we need\ndef formatFunctionSample(sample):\n    language = sample['language']\n    instruction = f\"What does this {language} function do?\"\n    inputText = sample['func_code_string']\n    outputText = sample['func_documentation_string']\n\n    # Returning a dictionary of the necessary columns\n    return {\n        \"instruction\": instruction,\n        \"input\": inputText,\n        \"output\": outputText\n    }\n\n# Define the function to create the new 'text' column\ndef createAlpacaFormatString(sample):\n    instruction = sample['instruction']\n    inputText = sample['input']\n    outputText = sample['output']\n    \n    text = alpacaFormatString.format(instruction, inputText, outputText) + EOS_TOKEN\n    sample['text'] = text\n    \n    return sample","metadata":{"execution":{"iopub.status.busy":"2024-07-26T11:55:47.509904Z","iopub.execute_input":"2024-07-26T11:55:47.510196Z","iopub.status.idle":"2024-07-26T11:55:47.801245Z","shell.execute_reply.started":"2024-07-26T11:55:47.510169Z","shell.execute_reply":"2024-07-26T11:55:47.800410Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset(\"claudios/code_search_net\", \"python\", split=\"train[:21]\")\n\n# Mapping the existing dataset to the new format keeping only the keys of the dictionary we returned\ndataset = dataset.map(formatFunctionSample, remove_columns=dataset.column_names)\n\n# Adding the text column to the new dataset\ndataset = dataset.map(createAlpacaFormatString)","metadata":{"execution":{"iopub.status.busy":"2024-07-26T11:55:47.802283Z","iopub.execute_input":"2024-07-26T11:55:47.803025Z","iopub.status.idle":"2024-07-26T11:55:58.452256Z","shell.execute_reply.started":"2024-07-26T11:55:47.802989Z","shell.execute_reply":"2024-07-26T11:55:58.451037Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/13.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50aa481ae3914f61b39b6c7ce5fb11dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/130M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"243bc95aa70c4726bb7a4ae3091b0a8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/135M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbf4aeaa33ca42beafa97284b2b7d0d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/125M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7f15c250d724762ac1e36ae614deec6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/21.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ae4b5f3114a4604aa579c47dcb4d684"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/23.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"838cbd326ab841e28f6e2043b7784b11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/412178 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1785a2ed66ea4a23ad50407a6f1e13df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/22176 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6740ff9e5a894ac9877b25749c6a344e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/23107 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"165f6d5e7c224633b823354f28baf117"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/21 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7be28bf96aa4ae3bf99e385a8d7dfd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/21 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f30de27d1054293a3ad8edfc027d138"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-07-26T11:55:58.453449Z","iopub.execute_input":"2024-07-26T11:55:58.453776Z","iopub.status.idle":"2024-07-26T11:55:58.460287Z","shell.execute_reply.started":"2024-07-26T11:55:58.453749Z","shell.execute_reply":"2024-07-26T11:55:58.459412Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['instruction', 'input', 'output', 'text'],\n    num_rows: 21\n})"},"metadata":{}}]},{"cell_type":"code","source":"pp.pp(dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-07-26T11:55:58.461326Z","iopub.execute_input":"2024-07-26T11:55:58.461630Z","iopub.status.idle":"2024-07-26T11:55:58.473249Z","shell.execute_reply.started":"2024-07-26T11:55:58.461605Z","shell.execute_reply":"2024-07-26T11:55:58.472310Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"{'instruction': 'What does this python function do?',\n 'input': 'def addidsuffix(self, idsuffix, recursive = True):\\n'\n          '        \"\"\"Appends a suffix to this element\\'s ID, and optionally '\n          'to all child IDs as well. There is sually no need to call this '\n          'directly, invoked implicitly by :meth:`copy`\"\"\"\\n'\n          '        if self.id: self.id += idsuffix\\n'\n          '        if recursive:\\n'\n          '            for e in self:\\n'\n          '                try:\\n'\n          '                    e.addidsuffix(idsuffix, recursive)\\n'\n          '                except Exception:\\n'\n          '                    pass',\n 'output': \"Appends a suffix to this element's ID, and optionally to all child \"\n           'IDs as well. There is sually no need to call this directly, '\n           'invoked implicitly by :meth:`copy`',\n 'text': 'Below is an instruction that describes a task, paired with an input '\n         'that provides further context. Write a response that appropriately '\n         'completes the request.\\n'\n         '\\n'\n         '### Instruction:\\n'\n         'What does this python function do?\\n'\n         '\\n'\n         '### Input:\\n'\n         'def addidsuffix(self, idsuffix, recursive = True):\\n'\n         '        \"\"\"Appends a suffix to this element\\'s ID, and optionally to '\n         'all child IDs as well. There is sually no need to call this '\n         'directly, invoked implicitly by :meth:`copy`\"\"\"\\n'\n         '        if self.id: self.id += idsuffix\\n'\n         '        if recursive:\\n'\n         '            for e in self:\\n'\n         '                try:\\n'\n         '                    e.addidsuffix(idsuffix, recursive)\\n'\n         '                except Exception:\\n'\n         '                    pass\\n'\n         '\\n'\n         '### Response:\\n'\n         \"Appends a suffix to this element's ID, and optionally to all child \"\n         'IDs as well. There is sually no need to call this directly, invoked '\n         'implicitly by :meth:`copy`<|eot_id|>'}\n","output_type":"stream"}]},{"cell_type":"code","source":"print(dataset[0]['text'])","metadata":{"execution":{"iopub.status.busy":"2024-07-26T11:55:58.474418Z","iopub.execute_input":"2024-07-26T11:55:58.474777Z","iopub.status.idle":"2024-07-26T11:55:58.483158Z","shell.execute_reply.started":"2024-07-26T11:55:58.474752Z","shell.execute_reply":"2024-07-26T11:55:58.482222Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nWhat does this python function do?\n\n### Input:\ndef addidsuffix(self, idsuffix, recursive = True):\n        \"\"\"Appends a suffix to this element's ID, and optionally to all child IDs as well. There is sually no need to call this directly, invoked implicitly by :meth:`copy`\"\"\"\n        if self.id: self.id += idsuffix\n        if recursive:\n            for e in self:\n                try:\n                    e.addidsuffix(idsuffix, recursive)\n                except Exception:\n                    pass\n\n### Response:\nAppends a suffix to this element's ID, and optionally to all child IDs as well. There is sually no need to call this directly, invoked implicitly by :meth:`copy`<|eot_id|>\n","output_type":"stream"}]},{"cell_type":"code","source":"datasetDictionary = dataset.train_test_split(test_size=0.33) ","metadata":{"execution":{"iopub.status.busy":"2024-07-26T11:55:58.485685Z","iopub.execute_input":"2024-07-26T11:55:58.485953Z","iopub.status.idle":"2024-07-26T11:55:58.508711Z","shell.execute_reply.started":"2024-07-26T11:55:58.485930Z","shell.execute_reply":"2024-07-26T11:55:58.507832Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"datasetDictionary","metadata":{"execution":{"iopub.status.busy":"2024-07-26T11:55:58.509856Z","iopub.execute_input":"2024-07-26T11:55:58.510118Z","iopub.status.idle":"2024-07-26T11:55:58.516494Z","shell.execute_reply.started":"2024-07-26T11:55:58.510095Z","shell.execute_reply":"2024-07-26T11:55:58.515623Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['instruction', 'input', 'output', 'text'],\n        num_rows: 14\n    })\n    test: Dataset({\n        features: ['instruction', 'input', 'output', 'text'],\n        num_rows: 7\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# args = TrainingArguments(\n#     per_device_train_batch_size = 2,\n#     per_device_eval_batch_size = 2,\n#     gradient_accumulation_steps = 4,\n#     eval_strategy=\"steps\",\n#     warmup_steps = 5,\n# #     max_steps = 10,\n# #     num_train_epochs = 2,\n#     learning_rate = 2e-4,\n#     fp16 = not torch.cuda.is_bf16_supported(),\n#     bf16 = torch.cuda.is_bf16_supported(),\n#     optim = \"adamw_8bit\",\n#     weight_decay = 0.01,\n#     lr_scheduler_type = \"linear\",\n#     seed = 42,\n#     output_dir = \"outputs\",\n#     report_to = \"none\",\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trainer = SFTTrainer(\n#     model = model,\n#     tokenizer = tokenizer,\n#     train_dataset = datasetDictionary[\"train\"],\n#     eval_dataset = datasetDictionary[\"test\"],\n#     dataset_text_field = \"text\",\n#     max_seq_length = max_seq_length,\n#     dataset_num_proc = 2,\n#     packing = True, # Packs short sequences together to save time!\n#     args = args,\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    dataset_num_proc = 2,\n    packing = False, # Can make training 5x faster for short sequences.\n    args = TrainingArguments(\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 5,\n        max_steps = 60,\n        learning_rate = 2e-4,\n        fp16 = not torch.cuda.is_bf16_supported(),\n        bf16 = torch.cuda.is_bf16_supported(),\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs\",\n        report_to = \"none\",\n    ),\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-26T11:56:18.848895Z","iopub.execute_input":"2024-07-26T11:56:18.849255Z","iopub.status.idle":"2024-07-26T11:56:20.357225Z","shell.execute_reply.started":"2024-07-26T11:56:18.849229Z","shell.execute_reply":"2024-07-26T11:56:20.356292Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/21 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc3defbaa2a3428886d70e2da5f3a4bf"}},"metadata":{}},{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"#@title Show current memory stats\nimport torch\ngpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\nprint(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\nprint(f\"{start_gpu_memory} GB of memory reserved.\")","metadata":{"execution":{"iopub.status.busy":"2024-07-26T11:56:24.766289Z","iopub.execute_input":"2024-07-26T11:56:24.766659Z","iopub.status.idle":"2024-07-26T11:56:24.777883Z","shell.execute_reply.started":"2024-07-26T11:56:24.766615Z","shell.execute_reply":"2024-07-26T11:56:24.776955Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"GPU = Tesla T4. Max memory = 14.741 GB.\n5.762 GB of memory reserved.\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-07-26T11:56:25.954355Z","iopub.execute_input":"2024-07-26T11:56:25.955078Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 21 | Num Epochs = 30\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 8 | Total steps = 60\n \"-____-\"     Number of trainable parameters = 83,886,080\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='37' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [37/60 07:51 < 05:09, 0.07 it/s, Epoch 13.09/30]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.495500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.626300</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.862400</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.965400</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.600200</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.483800</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.393600</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.369100</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.210700</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.956200</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.984700</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.907700</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.832800</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.836500</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.741300</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.840400</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.587200</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.597600</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.619700</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.571700</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.460600</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.480700</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.349200</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.434900</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.254800</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.397400</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.206600</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.198000</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.086600</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.231400</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>0.238000</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>0.099300</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>0.065400</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>0.145600</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.079200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"#@title Show final memory and time stats\nused_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nused_memory_for_lora = round(used_memory - start_gpu_memory, 3)\nused_percentage = round(used_memory         /max_memory*100, 3)\nlora_percentage = round(used_memory_for_lora/max_memory*100, 3)\nprint(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\nprint(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\nprint(f\"Peak reserved memory = {used_memory} GB.\")\nprint(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\nprint(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\nprint(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FastLanguageModel.for_inference(model) # Enable native 2x faster inference\ninputs = tokenizer(\n[\n    alpacaFormatString.format(\n        \"Continue the fibonnaci sequence.\", # instruction\n        \"1, 1, 2, 3, 5, 8\", # input\n        \"\", # output - leave this blank for generation!\n    )\n], return_tensors = \"pt\").to(\"cuda\")\n\nfrom transformers import TextStreamer\ntext_streamer = TextStreamer(tokenizer)\n_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}