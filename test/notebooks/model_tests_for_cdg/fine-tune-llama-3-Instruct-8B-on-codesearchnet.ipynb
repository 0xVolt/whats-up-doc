{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!mamba install --quiet --force-reinstall aiohttp -y\n!pip install -qU \"xformers<0.0.26\" --index-url https://download.pytorch.org/whl/cu121\n!pip install -q \"unsloth[kaggle-new] @ git+https://github.com/unslothai/unsloth.git\"\n# !pip install wandb evaluate accelerate\n\n# Temporary fix for https://github.com/huggingface/datasets/issues/6753\n!pip install datasets==2.16.0 fsspec==2023.10.0 gcsfs==2023.10.0 pprint","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-26T09:06:57.612369Z","iopub.execute_input":"2024-07-26T09:06:57.612733Z","iopub.status.idle":"2024-07-26T09:11:54.393254Z","shell.execute_reply.started":"2024-07-26T09:06:57.612704Z","shell.execute_reply":"2024-07-26T09:11:54.391947Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/c6f2354e.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/86b0f08d.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/c9ddbd6b.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/b121c3e7.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/497deca9.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/09cdf8bf.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/47929eba.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/3e39a7aa.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/2ce54b42.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/4ea078d6.json\" was modified by another program\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\n\u001b[33mWARNING: huggingface-hub 0.23.2 does not provide the extra 'hf-transfer'\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mCollecting datasets==2.16.0\n  Downloading datasets-2.16.0-py3-none-any.whl.metadata (20 kB)\nCollecting fsspec==2023.10.0\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nCollecting gcsfs==2023.10.0\n  Downloading gcsfs-2023.10.0-py2.py3-none-any.whl.metadata (1.6 kB)\n\u001b[31mERROR: Could not find a version that satisfies the requirement pprint (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for pprint\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nimport pprint as pp\nfrom datasets import load_dataset\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-07-26T09:14:23.573350Z","iopub.execute_input":"2024-07-26T09:14:23.573724Z","iopub.status.idle":"2024-07-26T09:14:23.578565Z","shell.execute_reply.started":"2024-07-26T09:14:23.573696Z","shell.execute_reply":"2024-07-26T09:14:23.577596Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"max_seq_length = 2048\ndtype = None\nload_in_4bit = True\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-26T09:12:23.396454Z","iopub.execute_input":"2024-07-26T09:12:23.397064Z","iopub.status.idle":"2024-07-26T09:12:53.663340Z","shell.execute_reply.started":"2024-07-26T09:12:23.397028Z","shell.execute_reply":"2024-07-26T09:12:53.662101Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"==((====))==  Unsloth: Fast Llama patching release 2024.8\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\nO^O/ \\_/ \\    Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.25.post1. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18052030a7a248c0be0ddb289736a4e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/131 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"458f3a5c7618491f8a7bcb50f47c406b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73f333b101fd41bcaf653ca325306f32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0167e195488479fbe07057433c806ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04b0a18c43da4d38bc2be89d75365903"}},"metadata":{}}]},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 32,\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0,\n    bias = \"none\",\n    use_gradient_checkpointing = \"unsloth\", # Set to True if out of memory\n    random_state = 3407,\n    use_rslora = False,\n    loftq_config = None,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-26T09:12:53.664652Z","iopub.execute_input":"2024-07-26T09:12:53.665002Z","iopub.status.idle":"2024-07-26T09:12:59.270766Z","shell.execute_reply.started":"2024-07-26T09:12:53.664968Z","shell.execute_reply":"2024-07-26T09:12:59.269733Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Unsloth 2024.8 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}]},{"cell_type":"code","source":"# EOS Token is required to stop open-ended generation and eventual hallucination\n# EOS_TOKEN = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-07-26T09:13:12.536151Z","iopub.execute_input":"2024-07-26T09:13:12.536839Z","iopub.status.idle":"2024-07-26T09:13:12.540729Z","shell.execute_reply.started":"2024-07-26T09:13:12.536806Z","shell.execute_reply":"2024-07-26T09:13:12.539783Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\n{}\n\n### Input:\n{}\n\n### Response:\n{}\"\"\"\n\nEOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN (<|eot_id|>)\ndef formatting_prompts_func(examples):\n    instructions = examples[\"instruction\"]\n    inputs       = examples[\"input\"]\n    outputs      = examples[\"output\"]\n    texts = []\n    for instruction, input, output in zip(instructions, inputs, outputs):\n        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n        texts.append(text)\n    return { \"text\" : texts, }\npass","metadata":{"execution":{"iopub.status.busy":"2024-07-26T09:13:12.789258Z","iopub.execute_input":"2024-07-26T09:13:12.789598Z","iopub.status.idle":"2024-07-26T09:13:12.796097Z","shell.execute_reply.started":"2024-07-26T09:13:12.789572Z","shell.execute_reply":"2024-07-26T09:13:12.795167Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset(\"yahma/alpaca-cleaned\", split = \"train[:21]\")\ndataset = dataset.map(formatting_prompts_func, batched = True,)","metadata":{"execution":{"iopub.status.busy":"2024-07-26T09:13:27.190215Z","iopub.execute_input":"2024-07-26T09:13:27.190608Z","iopub.status.idle":"2024-07-26T09:13:30.027491Z","shell.execute_reply.started":"2024-07-26T09:13:27.190580Z","shell.execute_reply":"2024-07-26T09:13:30.026487Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/11.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd5341afee2445ef9d55a9d207d72b5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/44.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be4964c809274e22893ace4614fefea1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/51760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdab3c242d8040eb9833fc191651a769"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/21 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42d4f664fc15453697153ba2b15a9314"}},"metadata":{}}]},{"cell_type":"code","source":"pp.pp(dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-07-26T09:33:35.673053Z","iopub.execute_input":"2024-07-26T09:33:35.673869Z","iopub.status.idle":"2024-07-26T09:33:35.680525Z","shell.execute_reply.started":"2024-07-26T09:33:35.673837Z","shell.execute_reply":"2024-07-26T09:33:35.679584Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"{'output': '1. Eat a balanced and nutritious diet: Make sure your meals are '\n           'inclusive of a variety of fruits and vegetables, lean protein, '\n           'whole grains, and healthy fats. This helps to provide your body '\n           'with the essential nutrients to function at its best and can help '\n           'prevent chronic diseases.\\n'\n           '\\n'\n           '2. Engage in regular physical activity: Exercise is crucial for '\n           'maintaining strong bones, muscles, and cardiovascular health. Aim '\n           'for at least 150 minutes of moderate aerobic exercise or 75 '\n           'minutes of vigorous exercise each week.\\n'\n           '\\n'\n           '3. Get enough sleep: Getting enough quality sleep is crucial for '\n           'physical and mental well-being. It helps to regulate mood, improve '\n           'cognitive function, and supports healthy growth and immune '\n           'function. Aim for 7-9 hours of sleep each night.',\n 'input': '',\n 'instruction': 'Give three tips for staying healthy.',\n 'text': 'Below is an instruction that describes a task, paired with an input '\n         'that provides further context. Write a response that appropriately '\n         'completes the request.\\n'\n         '\\n'\n         '### Instruction:\\n'\n         'Give three tips for staying healthy.\\n'\n         '\\n'\n         '### Input:\\n'\n         '\\n'\n         '\\n'\n         '### Response:\\n'\n         '1. Eat a balanced and nutritious diet: Make sure your meals are '\n         'inclusive of a variety of fruits and vegetables, lean protein, whole '\n         'grains, and healthy fats. This helps to provide your body with the '\n         'essential nutrients to function at its best and can help prevent '\n         'chronic diseases.\\n'\n         '\\n'\n         '2. Engage in regular physical activity: Exercise is crucial for '\n         'maintaining strong bones, muscles, and cardiovascular health. Aim '\n         'for at least 150 minutes of moderate aerobic exercise or 75 minutes '\n         'of vigorous exercise each week.\\n'\n         '\\n'\n         '3. Get enough sleep: Getting enough quality sleep is crucial for '\n         'physical and mental well-being. It helps to regulate mood, improve '\n         'cognitive function, and supports healthy growth and immune function. '\n         'Aim for 7-9 hours of sleep each night.<|eot_id|>'}\n","output_type":"stream"}]},{"cell_type":"code","source":"print(dataset[0]['text'])","metadata":{"execution":{"iopub.status.busy":"2024-07-26T09:15:52.050403Z","iopub.execute_input":"2024-07-26T09:15:52.051206Z","iopub.status.idle":"2024-07-26T09:15:52.057163Z","shell.execute_reply.started":"2024-07-26T09:15:52.051165Z","shell.execute_reply":"2024-07-26T09:15:52.056192Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|eot_id|>\n","output_type":"stream"}]},{"cell_type":"code","source":"args = TrainingArguments(\n    per_device_train_batch_size = 2,\n    per_device_eval_batch_size=2,\n    gradient_accumulation_steps = 4,\n    evaluation_strategy=\"steps\",\n    warmup_ratio = 0.1,\n    num_train_epochs = 1,\n    learning_rate = 2e-5,\n    fp16 = not torch.cuda.is_bf16_supported(),\n    bf16 = torch.cuda.is_bf16_supported(),\n    optim = \"adamw_8bit\",\n    weight_decay = 0.1,\n    lr_scheduler_type = \"linear\",\n    seed = 3407,\n    output_dir = \"outputs\",\n    logging_steps = 1,\n    logging_strategy = 'steps',\n    save_total_limit = 2,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T09:40:14.079634Z","iopub.status.idle":"2024-07-02T09:40:14.079992Z","shell.execute_reply.started":"2024-07-02T09:40:14.079802Z","shell.execute_reply":"2024-07-02T09:40:14.079816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset_dict[\"train\"],\n    eval_dataset = dataset_dict[\"test\"],\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    dataset_num_proc = 2,\n    packing = True, # Packs short sequences together to save time!\n    args = args,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T09:40:14.080794Z","iopub.status.idle":"2024-07-02T09:40:14.081129Z","shell.execute_reply.started":"2024-07-02T09:40:14.080970Z","shell.execute_reply":"2024-07-02T09:40:14.080984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@title Show current memory stats\ngpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\nprint(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\nprint(f\"{start_gpu_memory} GB of memory reserved.\")","metadata":{"execution":{"iopub.status.busy":"2024-07-02T09:40:14.082591Z","iopub.status.idle":"2024-07-02T09:40:14.082912Z","shell.execute_reply.started":"2024-07-02T09:40:14.082756Z","shell.execute_reply":"2024-07-02T09:40:14.082769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@title Show final memory and time stats\nused_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nused_memory_for_lora = round(used_memory - start_gpu_memory, 3)\nused_percentage = round(used_memory         /max_memory*100, 3)\nlora_percentage = round(used_memory_for_lora/max_memory*100, 3)\nprint(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\nprint(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\nprint(f\"Peak reserved memory = {used_memory} GB.\")\nprint(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\nprint(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\nprint(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FastLanguageModel.for_inference(model) # Enable native 2x faster inference\ninputs = tokenizer(\n[\n    alpaca_prompt.format(\n        \"Continue the fibonnaci sequence.\", # instruction\n        \"1, 1, 2, 3, 5, 8\", # input\n        \"\", # output - leave this blank for generation!\n    )\n], return_tensors = \"pt\").to(\"cuda\")\n\nfrom transformers import TextStreamer\ntext_streamer = TextStreamer(tokenizer)\n_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)","metadata":{},"execution_count":null,"outputs":[]}]}