{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!mamba install --force-reinstall aiohttp -y\n!pip install -U \"xformers<0.0.26\" --index-url https://download.pytorch.org/whl/cu121\n!pip install \"unsloth[kaggle-new] @ git+https://github.com/unslothai/unsloth.git\"\n# !pip install wandb evaluate accelerate\n\n# Temporary fix for https://github.com/huggingface/datasets/issues/6753\n!pip install datasets==2.16.0 fsspec==2023.10.0 gcsfs==2023.10.0\n\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-28T20:18:03.226100Z","iopub.execute_input":"2024-06-28T20:18:03.226622Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"\nLooking for: ['aiohttp']\n\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/c6f2354e.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\nrapidsai/linux-64 (check zst) \u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m   0.0 B @  ??.?MB/s Checking  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0Grapidsai/linux-64 (check zst)                       Checked  0.2s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/86b0f08d.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\nrapidsai/noarch (check zst) \u001b[90m━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━\u001b[0m   0.0 B @  ??.?MB/s Checking  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\nrapidsai/noarch (check zst) \u001b[90m━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━\u001b[0m   0.0 B @  ??.?MB/s Checking  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0Grapidsai/noarch (check zst)                         Checked  0.1s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/c9ddbd6b.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnvidia/linux-64 (check zst)                        Checked  0.1s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/b121c3e7.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\nnvidia/noarch (check zst) \u001b[90m━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━━\u001b[0m   0.0 B @  ??.?MB/s Checking  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnvidia/noarch (check zst)                           Checked  0.1s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/497deca9.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/09cdf8bf.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/47929eba.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/linux-64 (check zst)                     Checked  0.1s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/3e39a7aa.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\npkgs/main/noarch (check zst) \u001b[33m━━━━━━━━━━━━━━━━\u001b[0m   0.0 B @  ??.?MB/s Checking  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/noarch (check zst)                        Checked  0.0s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/2ce54b42.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/linux-64 (check zst)                        Checked  0.0s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/4ea078d6.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\npkgs/r/noarch (check zst) \u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m   0.0 B @  ??.?MB/s Checking  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/noarch (check zst)                           Checked  0.0s\n\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\nrapidsai/linux-64 \u001b[90m━━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\nconda-forge/linux-64 \u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\nrapidsai/linux-64    \u001b[90m━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\nrapidsai/noarch      \u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\nnvidia/linux-64      \u001b[90m━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\nnvidia/noarch        \u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnvidia/noarch                                        8.0kB @  65.9kB/s  0.1s\nrapidsai/noarch                                     11.5kB @  80.2kB/s  0.1s\nnvidia/linux-64                                    186.9kB @   1.2MB/s  0.2s\n[+] 0.2s\nconda-forge/linux-64 \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 151.3kB /  35.7MB @ 888.1kB/s  0.2s\nrapidsai/linux-64    ━╸\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m  46.5kB / 334.9kB @ 275.0kB/s  0.2s\npkgs/main/noarch     \u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\npkgs/r/linux-64      \u001b[90m━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\npkgs/r/noarch        \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Grapidsai/linux-64                                  334.9kB @   1.6MB/s  0.2s\npkgs/main/noarch                                   714.6kB @   2.7MB/s  0.1s\n[+] 0.3s\nconda-forge/linux-64 ╸\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   3.0MB /  35.7MB @  10.9MB/s  0.3s\nconda-forge/noarch   \u001b[90m━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\npkgs/main/linux-64   \u001b[90m━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\npkgs/r/linux-64      ╸\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 134.2kB /   1.6MB @ 508.1kB/s  0.1s\npkgs/r/noarch        ━━━━━━━━━━━━━━╸\u001b[90m━━━━━━━━\u001b[0m   1.4MB /   2.1MB @   5.0MB/s  0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/noarch                                        2.1MB @   7.1MB/s  0.2s\npkgs/r/linux-64                                      1.6MB @   4.3MB/s  0.2s\n[+] 0.4s\nconda-forge/linux-64 ━╸\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m   3.4MB /  35.7MB @  10.2MB/s  0.4s\nconda-forge/noarch   ╸\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   1.0MB /  15.2MB @   2.7MB/s  0.2s\npkgs/main/linux-64   ━━━╸\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m   1.3MB /   6.2MB @   3.3MB/s  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.5s\nconda-forge/linux-64 ━━╸\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m   5.9MB /  35.7MB @  12.9MB/s  0.5s\nconda-forge/noarch   ━━━╸\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m   3.2MB /  15.2MB @   6.8MB/s  0.3s\npkgs/main/linux-64   ━━━━━━━━━━━━╸\u001b[90m━━━━━━━━━━\u001b[0m   3.6MB /   6.2MB @   7.4MB/s  0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.6s\nconda-forge/linux-64 ━━━━╸\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m   8.9MB /  35.7MB @  15.8MB/s  0.6s\nconda-forge/noarch   ━━━━━━━╸\u001b[90m━━━━━━━━━━━━━━━\u001b[0m   6.0MB /  15.2MB @  10.4MB/s  0.4s\npkgs/main/linux-64   ━━━━━━━━━━━━━━━━━╸\u001b[90m━━━━━\u001b[0m   5.0MB /   6.2MB @   9.4MB/s  0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/linux-64                                   6.2MB @  10.7MB/s  0.4s\n[+] 0.7s\nconda-forge/linux-64 ━━━━╸\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m   9.4MB /  35.7MB @  14.2MB/s  0.7s\nconda-forge/noarch   ━━━━━━━━╸\u001b[90m━━━━━━━━━━━━━━\u001b[0m   6.2MB /  15.2MB @   9.4MB/s  0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.8s\nconda-forge/linux-64 ━━━━━━━━╸\u001b[90m━━━━━━━━━━━━━━\u001b[0m  15.1MB /  35.7MB @  19.8MB/s  0.8s\nconda-forge/noarch   ━━━━━━━━━━━━━╸\u001b[90m━━━━━━━━━\u001b[0m   9.8MB /  15.2MB @  12.8MB/s  0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.9s\nconda-forge/linux-64 ━━━━━━━━━━━━━━╸\u001b[90m━━━━━━━━\u001b[0m  24.0MB /  35.7MB @  27.7MB/s  0.9s\nconda-forge/noarch   ━━━━━━━━━━━━━╸\u001b[90m━━━━━━━━━\u001b[0m   9.8MB /  15.2MB @  11.3MB/s  0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.0s\nconda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━━\u001b[0m  31.5MB /  35.7MB @  32.4MB/s  1.0s\nconda-forge/noarch   ━━━━━━━━━━━━━━━╸\u001b[90m━━━━━━━\u001b[0m  10.9MB /  15.2MB @  11.2MB/s  0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.1s\nconda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━\u001b[0m  33.7MB /  35.7MB @  33.0MB/s  1.1s\nconda-forge/noarch   ━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━━\u001b[0m  13.4MB /  15.2MB @  13.1MB/s  0.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.2s\nconda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━\u001b[0m  33.7MB /  35.7MB @  33.0MB/s  1.2s\nconda-forge/noarch   ━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━━\u001b[0m  13.4MB /  15.2MB @  13.1MB/s  1.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.3s\nconda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━\u001b[0m  33.7MB /  35.7MB @  33.0MB/s  1.3s\nconda-forge/noarch   ━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━━\u001b[0m  13.4MB /  15.2MB @  13.1MB/s  1.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.4s\nconda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━\u001b[0m  33.7MB /  35.7MB @  33.0MB/s  1.4s\nconda-forge/noarch   ━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━━\u001b[0m  13.4MB /  15.2MB @  13.1MB/s  1.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/linux-64                                35.7MB @  33.5MB/s  1.4s\n[+] 1.5s\nconda-forge/noarch ━━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━━\u001b[0m  13.4MB /  15.2MB @  13.1MB/s  1.3s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/noarch                                  15.2MB @  14.3MB/s  1.4s\n\u001b[?25h\nPinned packages:\n  - python 3.10.*\n\n\nTransaction\n\n  Prefix: /opt/conda\n\n  Updating specs:\n\n   - aiohttp\n\n\n  Package    Version  Build            Channel           Size\n───────────────────────────────────────────────────────────────\n  Reinstall:\n───────────────────────────────────────────────────────────────\n\n  \u001b[32mo aiohttp\u001b[0m    3.9.1  py310h2372a71_0  conda-forge\u001b[32m     Cached\u001b[0m\n\n  Summary:\n\n  Reinstall: 1 packages\n\n  Total download: 0 B\n\n───────────────────────────────────────────────────────────────\n\n\n\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\nDownloading and Extracting Packages:\n\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nLooking in indexes: https://download.pytorch.org/whl/cu121\nCollecting xformers<0.0.26\n  Downloading https://download.pytorch.org/whl/cu121/xformers-0.0.25.post1-cp310-cp310-manylinux2014_x86_64.whl (222.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.5/222.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xformers<0.0.26) (1.26.4)\nCollecting torch==2.2.2 (from xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.2.2%2Bcu121-cp310-cp310-linux_x86_64.whl (757.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.3/757.3 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->xformers<0.0.26) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->xformers<0.0.26) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->xformers<0.0.26) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->xformers<0.0.26) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->xformers<0.0.26) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->xformers<0.0.26) (2024.3.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting triton==2.2.0 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvjitlink_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (19.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.2.2->xformers<0.0.26) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.2.2->xformers<0.0.26) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nmax_seq_length = 2048\ndtype = None\nload_in_4bit = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 32,\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0,\n    bias = \"none\",\n    use_gradient_checkpointing = \"unsloth\",                       # Set to True if out of memory\n    random_state = 3407,\n    use_rslora = False,\n    loftq_config = None,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T23:33:43.351170Z","iopub.execute_input":"2024-06-26T23:33:43.351482Z","iopub.status.idle":"2024-06-26T23:33:48.701180Z","shell.execute_reply.started":"2024-06-26T23:33:43.351455Z","shell.execute_reply":"2024-06-26T23:33:48.700254Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\n{}\n\n### Input:\n{}\n\n### Response:\n{}\"\"\"\n\nEOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n\ndef formatting_prompts_func(examples):\n    instructions = examples[\"instruction\"]\n    inputs       = examples[\"input\"]\n    outputs      = examples[\"output\"]\n    texts = []\n    for instruction, input, output in zip(instructions, inputs, outputs):\n        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n        texts.append(text)\n    return { \"text\" : texts, }\npass\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"yahma/alpaca-cleaned\", split = \"train\")\ndataset = dataset.map(formatting_prompts_func, batched = True,)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T23:33:48.702312Z","iopub.execute_input":"2024-06-26T23:33:48.702613Z","iopub.status.idle":"2024-06-26T23:33:51.763752Z","shell.execute_reply.started":"2024-06-26T23:33:48.702586Z","shell.execute_reply":"2024-06-26T23:33:51.762803Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/11.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cf20bfbdb6f48fc8b0679c94b433e56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/44.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64882c7c63d044a6abd0187515694954"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e96606db30de4656921ac2b9f960868f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/51760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cba938004909432abdc084ac43143e88"}},"metadata":{}}]},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    dataset_num_proc = 2,\n    packing = False, # Can make training 5x faster for short sequences.\n    args = TrainingArguments(\n        report_to = 'wandb',\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 5,\n        max_steps = 60,\n        learning_rate = 2e-4,\n        fp16 = not torch.cuda.is_bf16_supported(),\n        bf16 = torch.cuda.is_bf16_supported(),\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs\",\n        report_to = \"none\",\n    ),\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T23:34:08.134182Z","iopub.execute_input":"2024-06-26T23:34:08.134564Z","iopub.status.idle":"2024-06-26T23:34:08.143381Z","shell.execute_reply.started":"2024-06-26T23:34:08.134535Z","shell.execute_reply":"2024-06-26T23:34:08.142069Z"},"trusted":true},"execution_count":13,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[13], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    report_to = \"none\",\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword argument repeated: report_to\n"],"ename":"SyntaxError","evalue":"keyword argument repeated: report_to (145528703.py, line 27)","output_type":"error"}]},{"cell_type":"code","source":"#@title Show current memory stats\ngpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\nprint(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\nprint(f\"{start_gpu_memory} GB of memory reserved.\")","metadata":{},"execution_count":null,"outputs":[]}]}