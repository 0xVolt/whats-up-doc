{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!mamba install --force-reinstall aiohttp -y\n!pip install -U \"xformers<0.0.26\" --index-url https://download.pytorch.org/whl/cu121\n!pip install \"unsloth[kaggle-new] @ git+https://github.com/unslothai/unsloth.git\"\n!pip install wandb evaluate accelerate\n\n# Temporary fix for https://github.com/huggingface/datasets/issues/6753\n!pip install datasets==2.16.0 fsspec==2023.10.0 gcsfs==2023.10.0\n\nimport os\nimport wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-26T23:27:28.905334Z","iopub.execute_input":"2024-06-26T23:27:28.905729Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"\nLooking for: ['aiohttp']\n\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/c6f2354e.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\nrapidsai/linux-64 (check zst) \u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m   0.0 B @  ??.?MB/s Checking  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0Grapidsai/linux-64 (check zst)                       Checked  0.1s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/86b0f08d.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\nrapidsai/noarch (check zst) \u001b[90m╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━━\u001b[0m   0.0 B @  ??.?MB/s Checking  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0Grapidsai/noarch (check zst)                         Checked  0.1s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/c9ddbd6b.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnvidia/linux-64 (check zst)                        Checked  0.0s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/b121c3e7.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnvidia/noarch (check zst)                          Checked  0.1s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/497deca9.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/09cdf8bf.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/47929eba.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/linux-64 (check zst)                     Checked  0.1s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/3e39a7aa.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\npkgs/main/noarch (check zst) \u001b[90m━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━\u001b[0m   0.0 B @  ??.?MB/s Checking  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/noarch (check zst)                        Checked  0.0s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/2ce54b42.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/linux-64 (check zst)                        Checked  0.0s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/4ea078d6.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\npkgs/r/noarch (check zst) \u001b[90m━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━━\u001b[0m   0.0 B @  ??.?MB/s Checking  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/noarch (check zst)                           Checked  0.0s\n\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\nrapidsai/linux-64 \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\nconda-forge/linux-64 \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m   0.0 B @  ??.?MB/s             0.1s\nrapidsai/linux-64    \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m   0.0 B @  ??.?MB/s             0.1s\nrapidsai/noarch      \u001b[90m━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━\u001b[0m   0.0 B @  ??.?MB/s             0.1s\nnvidia/linux-64      \u001b[90m━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m   0.0 B @  ??.?MB/s             0.1s\nnvidia/noarch        ━━━━━━━━━━━━━━━━━━━━━━   8.0kB @  80.5kB/s Downloaded  0.1s\npkgs/r/noarch        \u001b[90m━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━\u001b[0m   0.0 B @  ??.?MB/s             0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnvidia/noarch                                      @  80.5kB/s  0.1s\nnvidia/linux-64                                    @   1.3MB/s  0.1s\nrapidsai/noarch                                    @  78.4kB/s  0.1s\n[+] 0.2s\nconda-forge/linux-64 \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 490.6kB /  35.6MB @   3.2MB/s  0.2s\nconda-forge/noarch   \u001b[90m━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\nrapidsai/linux-64    ━━━━╸\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m  77.8kB / 334.9kB @ 515.5kB/s  0.2s\npkgs/main/linux-64   \u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\npkgs/r/linux-64      \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\npkgs/r/noarch        \u001b[90m━━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Grapidsai/linux-64                                  334.9kB @   1.7MB/s  0.2s\n[+] 0.3s\nconda-forge/linux-64 ━╸\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m   4.4MB /  35.6MB @  16.9MB/s  0.3s\nconda-forge/noarch   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 179.8kB /  15.2MB @ 713.8kB/s  0.2s\npkgs/main/linux-64   \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\npkgs/main/noarch     \u001b[90m━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\npkgs/r/linux-64      ━╸\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m 171.2kB /   1.6MB @ 681.4kB/s  0.2s\npkgs/r/noarch        ━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━━\u001b[0m   1.8MB /   2.1MB @   6.9MB/s  0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/noarch                                        2.1MB @   7.3MB/s  0.2s\npkgs/r/linux-64                                      1.6MB @   4.5MB/s  0.2s\n[+] 0.4s\nconda-forge/linux-64 ━━╸\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m   5.9MB @  15.4MB/s             0.4s\nconda-forge/noarch   ━╸\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m   1.9MB @   5.0MB/s             0.3s\npkgs/main/linux-64   ━╸\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m 687.0kB @   1.8MB/s             0.2s\npkgs/main/noarch     ━━━━━━━━━━━━━━━━━━━━━━ 714.6kB @   1.8MB/s Downloaded  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/noarch                                   @   1.8MB/s  0.1s\n[+] 0.5s\nconda-forge/linux-64 ━━━━╸\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m   8.4MB /  35.6MB @  17.0MB/s  0.5s\nconda-forge/noarch   ━━━━━╸\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m   4.4MB /  15.2MB @   8.9MB/s  0.4s\npkgs/main/linux-64   ━━━━━━━━━━╸\u001b[90m━━━━━━━━━━━━\u001b[0m   3.2MB /   6.2MB @   6.4MB/s  0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.6s\nconda-forge/linux-64 ━━━━━╸\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m   9.8MB /  35.6MB @  17.9MB/s  0.6s\nconda-forge/noarch   ━━━━━━━╸\u001b[90m━━━━━━━━━━━━━━━\u001b[0m   5.9MB /  15.2MB @  10.6MB/s  0.5s\npkgs/main/linux-64   ━━━━━━━━━━━━━━━━╸\u001b[90m━━━━━━\u001b[0m   4.6MB /   6.2MB @   8.4MB/s  0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/linux-64                                   6.2MB @  10.2MB/s  0.5s\n[+] 0.7s\nconda-forge/linux-64 ━━━━━━╸\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m  11.6MB /  35.6MB @  16.9MB/s  0.7s\nconda-forge/noarch   ━━━━━━━━━━╸\u001b[90m━━━━━━━━━━━━\u001b[0m   7.7MB /  15.2MB @  11.1MB/s  0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.8s\nconda-forge/linux-64 ━━━━━━━━━╸\u001b[90m━━━━━━━━━━━━━\u001b[0m  16.0MB /  35.6MB @  20.2MB/s  0.8s\nconda-forge/noarch   ━━━━━━━━━━━━━━━━╸\u001b[90m━━━━━━\u001b[0m  12.0MB /  15.2MB @  15.1MB/s  0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.9s\nconda-forge/linux-64 ━━━━━━━━━━╸\u001b[90m━━━━━━━━━━━━\u001b[0m  18.3MB /  35.6MB @  21.6MB/s  0.9s\nconda-forge/noarch   ━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━\u001b[0m  14.3MB /  15.2MB @  16.8MB/s  0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.0s\nconda-forge/linux-64 ━━━━━━━━━━╸\u001b[90m━━━━━━━━━━━━\u001b[0m  18.3MB /  35.6MB @  21.6MB/s  1.0s\nconda-forge/noarch   ━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━\u001b[0m  14.3MB /  15.2MB @  16.8MB/s  0.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/noarch                                  15.2MB @  17.5MB/s  0.9s\n[+] 1.1s\nconda-forge/linux-64 ━━━━━━━━━━━━━━╸\u001b[90m━━━━━━━━\u001b[0m  23.6MB /  35.6MB @  22.3MB/s  1.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.2s\nconda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━━\u001b[0m  31.4MB /  35.6MB @  27.1MB/s  1.2s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.3s\nconda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━\u001b[0m  35.6MB /  35.6MB @  29.5MB/s  1.3s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.4s\nconda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━\u001b[0m  35.6MB /  35.6MB @  29.5MB/s  1.4s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.5s\nconda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━\u001b[0m  35.6MB /  35.6MB @  29.5MB/s  1.5s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/linux-64                                35.6MB @  29.5MB/s  1.6s\n\u001b[?25h\nPinned packages:\n  - python 3.10.*\n\n\nTransaction\n\n  Prefix: /opt/conda\n\n  Updating specs:\n\n   - aiohttp\n\n\n  Package    Version  Build            Channel           Size\n───────────────────────────────────────────────────────────────\n  Reinstall:\n───────────────────────────────────────────────────────────────\n\n  \u001b[32mo aiohttp\u001b[0m    3.9.1  py310h2372a71_0  conda-forge\u001b[32m     Cached\u001b[0m\n\n  Summary:\n\n  Reinstall: 1 packages\n\n  Total download: 0 B\n\n───────────────────────────────────────────────────────────────\n\n\n\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\nDownloading and Extracting Packages:\n\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nLooking in indexes: https://download.pytorch.org/whl/cu121\nCollecting xformers<0.0.26\n  Downloading https://download.pytorch.org/whl/cu121/xformers-0.0.25.post1-cp310-cp310-manylinux2014_x86_64.whl (222.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.5/222.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xformers<0.0.26) (1.26.4)\nCollecting torch==2.2.2 (from xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.2.2%2Bcu121-cp310-cp310-linux_x86_64.whl (757.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.3/757.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->xformers<0.0.26) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->xformers<0.0.26) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->xformers<0.0.26) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->xformers<0.0.26) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->xformers<0.0.26) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->xformers<0.0.26) (2024.3.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}]},{"cell_type":"code","source":"# set the wandb project where this run will be logged\nos.environ[\"WANDB_PROJECT\"] = \"fine-tune-llama-3-codesearchnet\"\n\n# save your trained model checkpoint to wandb\nos.environ[\"WANDB_LOG_MODEL\"] = \"true\"\n\n# turn off watch to log faster\nos.environ[\"WANDB_WATCH\"] = \"false\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nmax_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    use_gradient_checkpointing = \"unsloth\", # 4x longer contexts auto supported!\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}