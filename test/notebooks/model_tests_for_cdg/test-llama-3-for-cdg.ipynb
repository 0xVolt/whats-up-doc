{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Run Inference on Llama-3-8B-Instruct","metadata":{}},{"cell_type":"markdown","source":"## References\n1. [Model Card on HuggingFace](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)","metadata":{}},{"cell_type":"markdown","source":"## Install and Load Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install -q accelerate","metadata":{"execution":{"iopub.status.busy":"2024-06-15T08:28:56.689891Z","iopub.execute_input":"2024-06-15T08:28:56.690549Z","iopub.status.idle":"2024-06-15T08:29:09.617511Z","shell.execute_reply.started":"2024-06-15T08:28:56.690520Z","shell.execute_reply":"2024-06-15T08:29:09.616352Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom datetime import datetime\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\nfrom huggingface_hub import notebook_login as hfl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-15T08:29:12.928060Z","iopub.execute_input":"2024-06-15T08:29:12.928430Z","iopub.status.idle":"2024-06-15T08:29:28.552297Z","shell.execute_reply.started":"2024-06-15T08:29:12.928396Z","shell.execute_reply":"2024-06-15T08:29:28.551543Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-06-15 08:29:18.101209: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-15 08:29:18.101340: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-15 08:29:18.207548: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"hfl()","metadata":{"execution":{"iopub.status.busy":"2024-06-15T08:29:31.346413Z","iopub.execute_input":"2024-06-15T08:29:31.347383Z","iopub.status.idle":"2024-06-15T08:29:31.368223Z","shell.execute_reply.started":"2024-06-15T08:29:31.347351Z","shell.execute_reply":"2024-06-15T08:29:31.367286Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9417aaf02ef4b918a7cf7adbe08aa18"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Import Model and Tokenizer","metadata":{}},{"cell_type":"code","source":"checkpoint = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    checkpoint,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T08:29:40.404985Z","iopub.execute_input":"2024-06-15T08:29:40.405330Z","iopub.status.idle":"2024-06-15T08:32:13.512758Z","shell.execute_reply.started":"2024-06-15T08:29:40.405302Z","shell.execute_reply":"2024-06-15T08:32:13.512009Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0990f02f6f74cfcb3b703c3daec48bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb250d48cad54286b827123ca81efddc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7d3af7ca98e4d68b28f51544ba6c5d5"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a302d9b3f48f40a8a8f2838991281649"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d768c2e2113240ca9df620d86d21533a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2553d0b8e49e4845b49848300a6591e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02c1dea197054a32be264cabe48fb834"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"387dc4da0c614600bfc5fe90bdfc3ea1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad41564d380a4af8a3da39a9b707ccb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f82c07552fa42389c9758bfa133cc1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96bbfce851134dbda3da06bd351dd816"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29a366c04aa3412dbd5a707094be058b"}},"metadata":{}}]},{"cell_type":"code","source":"print(f\"Memory footprint: {model.get_memory_footprint() / 1e6:.2f} MB\")","metadata":{"execution":{"iopub.status.busy":"2024-06-15T08:32:22.097876Z","iopub.execute_input":"2024-06-15T08:32:22.098751Z","iopub.status.idle":"2024-06-15T08:32:22.106899Z","shell.execute_reply.started":"2024-06-15T08:32:22.098715Z","shell.execute_reply":"2024-06-15T08:32:22.105956Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Memory footprint: 16060.53 MB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Create Test Prompt","metadata":{}},{"cell_type":"code","source":"prompt = \"\"\"\nWrite a script in Python that implements a circular queue and creates one with user input. Give an example of how the script works and document the code with appropriate comments and docstrings wherever necessary. \nGenerate a response only for the prompt that is given and nothing else. \n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:29:54.303581Z","iopub.execute_input":"2024-06-12T11:29:54.304345Z","iopub.status.idle":"2024-06-12T11:29:54.308760Z","shell.execute_reply.started":"2024-06-12T11:29:54.304300Z","shell.execute_reply":"2024-06-12T11:29:54.307860Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"messages = [\n    {\"role\": \"system\", \"content\": \"You are a helpful and masterful programming assistant that generates markdown documentation for any input program.\"},\n    {\"role\": \"user\", \"content\": prompt},\n]","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:29:55.368579Z","iopub.execute_input":"2024-06-12T11:29:55.368916Z","iopub.status.idle":"2024-06-12T11:29:55.373504Z","shell.execute_reply.started":"2024-06-12T11:29:55.368889Z","shell.execute_reply":"2024-06-12T11:29:55.372586Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Run Inference with `model.generate()`","metadata":{}},{"cell_type":"code","source":"input_ids = tokenizer.apply_chat_template(\n    messages,\n    add_generation_prompt=True,\n    return_tensors=\"pt\"\n).to(model.device)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:29:56.860064Z","iopub.execute_input":"2024-06-12T11:29:56.860524Z","iopub.status.idle":"2024-06-12T11:29:56.934008Z","shell.execute_reply.started":"2024-06-12T11:29:56.860493Z","shell.execute_reply":"2024-06-12T11:29:56.933084Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"terminators = [\n    tokenizer.eos_token_id,\n    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n]","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:29:57.739635Z","iopub.execute_input":"2024-06-12T11:29:57.740235Z","iopub.status.idle":"2024-06-12T11:29:57.745655Z","shell.execute_reply.started":"2024-06-12T11:29:57.740205Z","shell.execute_reply":"2024-06-12T11:29:57.744672Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"%%time\noutputs = model.generate(\n    input_ids,\n    max_new_tokens=256,\n    eos_token_id=terminators,\n    do_sample=True,\n    temperature=0.6,\n    top_p=0.9,\n)\nresponse = outputs[0][input_ids.shape[-1]:]","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:30:02.661645Z","iopub.execute_input":"2024-06-12T11:30:02.662013Z","iopub.status.idle":"2024-06-12T11:30:21.706445Z","shell.execute_reply.started":"2024-06-12T11:30:02.661982Z","shell.execute_reply":"2024-06-12T11:30:21.705486Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 18.3 s, sys: 39.6 ms, total: 18.3 s\nWall time: 19 s\n","output_type":"stream"}]},{"cell_type":"code","source":"print(tokenizer.decode(response, skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:30:21.708134Z","iopub.execute_input":"2024-06-12T11:30:21.708442Z","iopub.status.idle":"2024-06-12T11:30:21.713889Z","shell.execute_reply.started":"2024-06-12T11:30:21.708409Z","shell.execute_reply":"2024-06-12T11:30:21.712847Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Here is a Python script that implements a circular queue and creates one with user input:\n```\nclass CircularQueue:\n    \"\"\"\n    A circular queue implementation in Python.\n    \"\"\"\n    def __init__(self, size):\n        \"\"\"\n        Initialize the circular queue with a given size.\n\n        Args:\n            size (int): The size of the queue.\n        \"\"\"\n        self.size = size\n        self.queue = [None] * size\n        self.front = 0\n        self.rear = 0\n\n    def is_full(self):\n        \"\"\"\n        Check if the queue is full.\n\n        Returns:\n            bool: True if the queue is full, False otherwise.\n        \"\"\"\n        return (self.rear + 1) % self.size == self.front\n\n    def is_empty(self):\n        \"\"\"\n        Check if the queue is empty.\n\n        Returns:\n            bool: True if the queue is empty, False otherwise.\n        \"\"\"\n        return self.front == self.rear\n\n    def enqueue(self, item):\n        \"\"\"\n        Enqueue an item into the queue.\n\n        Args:\n            item: The item to be enqueued.\n        \"\"\"\n        if self.is_full():\n            print(\"Queue is full. Cannot enqueue.\")\n            return\n        self.queue[self.rear]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Test Generate with Custom Input","metadata":{}},{"cell_type":"code","source":"language = \"Python\"\ncode = \"\"\"\ndef test_euler_method(self):\n    def dydx(x, y):\n        return x + y\n\n    x0, y0 = 0, 1\n    x_end = 1\n    h = 0.01\n    x, y = differential_equations.euler_method(dydx, x0, y0, x_end, h)\n    expected = np.exp(x_end) - x_end - 1  # Analytical solution for the differential equation dy/dx = x + y\n    self.assertAlmostEqual(y[-1], expected, places=2)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-06-15T08:33:02.098478Z","iopub.execute_input":"2024-06-15T08:33:02.099151Z","iopub.status.idle":"2024-06-15T08:33:02.104292Z","shell.execute_reply.started":"2024-06-15T08:33:02.099098Z","shell.execute_reply":"2024-06-15T08:33:02.103296Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"testAbstractCode = \"\"\"\ndef f(self):\n    def a(x, y):\n        return x + y\n\n    x0, y0 = 0, 1\n    x_end = 1\n    h = 0.01\n    x, y = differential_equations.euler_method(dydx, x0, y0, x_end, h)\n    expected = np.exp(x_end) - x_end - 1\n    self.assertAlmostEqual(y[-1], expected, places=2)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-06-15T08:33:02.766255Z","iopub.execute_input":"2024-06-15T08:33:02.767005Z","iopub.status.idle":"2024-06-15T08:33:02.772495Z","shell.execute_reply.started":"2024-06-15T08:33:02.766973Z","shell.execute_reply":"2024-06-15T08:33:02.771699Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"prompt = f\"\"\"\nGiven a script file in {language}, generate its documentation for each function. For each function in the script, document its name, arguments, return values, and a brief explanation of its logic. Ensure that code within comments is not parsed and documented. Generate nothing else than what is asked.\n\nStrictly use the following format for each function:\n\n## Function Name: `function_name`\n\n### Arguments\n* `arg1` (type): Description of argument 1.\n* `arg2` (type): Description of argument 2.\n* ...\n\n### Return Values\n* `return_value1` (type): Description of return value 1.\n* `return_value2` (type): Description of return value 2.\n* ...\n\n### Explanation of Function Logic:\n1. Brief explanation of the function logic step by step.\n2. ...\n3. ...\n\n-----------------------------------------------------------------------------\n\nHere is the function I want you to generate documentation of:\n\n{testAbstractCode}\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-06-15T08:33:03.369410Z","iopub.execute_input":"2024-06-15T08:33:03.369992Z","iopub.status.idle":"2024-06-15T08:33:03.374813Z","shell.execute_reply.started":"2024-06-15T08:33:03.369958Z","shell.execute_reply":"2024-06-15T08:33:03.373934Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"prompt","metadata":{"execution":{"iopub.status.busy":"2024-06-15T08:33:04.238999Z","iopub.execute_input":"2024-06-15T08:33:04.239346Z","iopub.status.idle":"2024-06-15T08:33:04.245997Z","shell.execute_reply.started":"2024-06-15T08:33:04.239317Z","shell.execute_reply":"2024-06-15T08:33:04.245022Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'\\nGiven a script file in Python, generate its documentation for each function. For each function in the script, document its name, arguments, return values, and a brief explanation of its logic. Ensure that code within comments is not parsed and documented. Generate nothing else than what is asked.\\n\\nStrictly use the following format for each function:\\n\\n## Function Name: `function_name`\\n\\n### Arguments\\n* `arg1` (type): Description of argument 1.\\n* `arg2` (type): Description of argument 2.\\n* ...\\n\\n### Return Values\\n* `return_value1` (type): Description of return value 1.\\n* `return_value2` (type): Description of return value 2.\\n* ...\\n\\n### Explanation of Function Logic:\\n1. Brief explanation of the function logic step by step.\\n2. ...\\n3. ...\\n\\n-----------------------------------------------------------------------------\\n\\nHere is the function I want you to generate documentation of:\\n\\n\\ndef f(self):\\n    def a(x, y):\\n        return x + y\\n\\n    x0, y0 = 0, 1\\n    x_end = 1\\n    h = 0.01\\n    x, y = differential_equations.euler_method(dydx, x0, y0, x_end, h)\\n    expected = np.exp(x_end) - x_end - 1\\n    self.assertAlmostEqual(y[-1], expected, places=2)\\n\\n'"},"metadata":{}}]},{"cell_type":"code","source":"%%time\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a helpful and masterful programming assistant that generates markdown documentation for any input program.\"},\n    {\"role\": \"user\", \"content\": prompt},\n]\n\ninput_ids = tokenizer.apply_chat_template(\n    messages,\n    add_generation_prompt=True,\n    return_tensors=\"pt\"\n).to(model.device)\n\nterminators = [\n    tokenizer.eos_token_id,\n    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n]\n\noutputs = model.generate(\n    input_ids,\n    max_new_tokens=1024,\n    eos_token_id=terminators,\n    do_sample=True,\n    temperature=0.6,\n    top_p=0.9,\n)\nresponse = outputs[0][input_ids.shape[-1]:]","metadata":{"execution":{"iopub.status.busy":"2024-06-15T08:33:05.721258Z","iopub.execute_input":"2024-06-15T08:33:05.722107Z","iopub.status.idle":"2024-06-15T08:33:21.876346Z","shell.execute_reply.started":"2024-06-15T08:33:05.722073Z","shell.execute_reply":"2024-06-15T08:33:21.875419Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 15.6 s, sys: 76.1 ms, total: 15.7 s\nWall time: 16.1 s\n","output_type":"stream"}]},{"cell_type":"code","source":"print(tokenizer.decode(response, skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-06-15T08:33:24.106505Z","iopub.execute_input":"2024-06-15T08:33:24.107389Z","iopub.status.idle":"2024-06-15T08:33:24.113533Z","shell.execute_reply.started":"2024-06-15T08:33:24.107354Z","shell.execute_reply":"2024-06-15T08:33:24.112475Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"## Function Name: `f`\n\n### Arguments\n* `self` (object): Description of the object instance.\n* No other arguments.\n\n### Return Values\n* No return values.\n\n### Explanation of Function Logic:\n1. The function defines a nested function `a` that takes two arguments `x` and `y` and returns their sum.\n2. It then initializes several variables: `x0`, `y0` to 0 and 1 respectively, `x_end` to 1, and `h` to 0.01.\n3. It uses the `euler_method` function from `differential_equations` module to solve a differential equation, passing `dydx`, `x0`, `y0`, `x_end`, and `h` as arguments.\n4. It calculates the expected value using `np.exp(x_end) - x_end - 1`.\n5. Finally, it asserts that the last element of the solution `y` is close to the expected value using `assertAlmostEqual`.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Remarks\n\n- This model works beautifully for our use case\n- We need a way to objectively quantify it's performance however","metadata":{}}]}