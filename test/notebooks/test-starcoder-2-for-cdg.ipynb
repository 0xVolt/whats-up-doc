{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Run Inference on StarCoder2-7B","metadata":{}},{"cell_type":"markdown","source":"## Install and Load Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install accelerate","metadata":{"execution":{"iopub.status.busy":"2024-06-11T13:49:18.358371Z","iopub.execute_input":"2024-06-11T13:49:18.359090Z","iopub.status.idle":"2024-06-11T13:49:32.238579Z","shell.execute_reply.started":"2024-06-11T13:49:18.359056Z","shell.execute_reply":"2024-06-11T13:49:32.237427Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.30.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom datetime import datetime\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-11T13:49:32.240348Z","iopub.execute_input":"2024-06-11T13:49:32.240640Z","iopub.status.idle":"2024-06-11T13:49:52.920730Z","shell.execute_reply.started":"2024-06-11T13:49:32.240613Z","shell.execute_reply":"2024-06-11T13:49:52.919974Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-06-11 13:49:39.965166: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-11 13:49:39.965262: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-11 13:49:40.146068: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Import Model and Tokenizer","metadata":{}},{"cell_type":"code","source":"checkpoint = \"bigcode/starcoder2-7b\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n# for fp16 use `torch_dtype=torch.float16` instead\nmodel = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=\"auto\", torch_dtype=torch.float16)","metadata":{"execution":{"iopub.status.busy":"2024-06-11T13:49:52.921766Z","iopub.execute_input":"2024-06-11T13:49:52.922330Z","iopub.status.idle":"2024-06-11T13:52:24.398522Z","shell.execute_reply.started":"2024-06-11T13:49:52.922303Z","shell.execute_reply":"2024-06-11T13:52:24.397769Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.88k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6407e2797444d0ca835817773927ee6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/777k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1bf25e6d8f04523a739b9643dd818da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/442k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d526ed8f89424fb2904f98c450c30539"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6949763e14b7485f9b11c7de9f241ce7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/958 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3454574f089448b5a10f344a75c314f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/893 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a688c3b4b01458780c083c7d2eb1e45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/41.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a704576c2f1f4c8b9bcdf436f0b6a118"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48d816bf9e574efeaf2c17af02f4e168"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.89G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f904c37fc7f24a0c8569c7ec4b00b160"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93d72fb3be00481fa700739262458430"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.51G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0428e3a1b57f46db828abbc25f0411e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"604cdd7637b343b7b4c4388e21659447"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71d631df83ba495da0e42d6d1e7c1b5f"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Create Test Prompt","metadata":{}},{"cell_type":"code","source":"prompt = \"\"\"\nWrite a script in Python that implements a circular queue and creates one with user input. Give an example of how the script works and document the code with appropriate comments and docstrings wherever necessary. \nGenerate a response only for the prompt that is given and nothing else. \n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-06-11T11:44:25.466191Z","iopub.execute_input":"2024-06-11T11:44:25.466575Z","iopub.status.idle":"2024-06-11T11:44:25.471008Z","shell.execute_reply.started":"2024-06-11T11:44:25.466549Z","shell.execute_reply":"2024-06-11T11:44:25.470067Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"## Run Inference with `model.generate()`","metadata":{}},{"cell_type":"code","source":"%%time\ninputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\noutputs = model.generate(inputs, max_new_tokens=256)\nprint(tokenizer.decode(outputs[0]))","metadata":{"execution":{"iopub.status.busy":"2024-06-11T11:32:21.781684Z","iopub.execute_input":"2024-06-11T11:32:21.782068Z","iopub.status.idle":"2024-06-11T11:32:37.837203Z","shell.execute_reply.started":"2024-06-11T11:32:21.782040Z","shell.execute_reply":"2024-06-11T11:32:37.836279Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nQuestion: Write a script in Python that implements a circular queue and creates one with user input.\nAnswer:\n\n```\nclass CircularQueue:\n    def __init__(self, size):\n        self.size = size\n        self.queue = [None] * size\n        self.front = 0\n        self.rear = 0\n\n    def enqueue(self, data):\n        if self.is_full():\n            print(\"Queue is full\")\n            return\n        self.queue[self.rear] = data\n        self.rear = (self.rear + 1) % self.size\n\n    def dequeue(self):\n        if self.is_empty():\n            print(\"Queue is empty\")\n            return\n        data = self.queue[self.front]\n        self.front = (self.front + 1) % self.size\n        return data\n\n    def is_empty(self):\n        return self.front == self.rear\n\n    def is_full(self):\n        return (self.rear + 1) % self.size == self.front\n\n    def print_queue(self):\n        if self.is_empty():\n            print(\"Queue is empty\")\n            return\n        print(\"Queue:\")\n        for i in range(self.front, self.rear):\n            print(self.queue[i], end=\" \")\n        print()\nCPU times: user 16 s, sys: 0 ns, total: 16 s\nWall time: 16.1 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Run Inference with Pipeline","metadata":{}},{"cell_type":"code","source":"def generateOutputWithModelPipeline(model, tokenizer, prompt, temperature=0.7, max_new_tokens=256) : \n    pipe = pipeline(\n        task=\"text-generation\", \n        model=model, \n        tokenizer=tokenizer\n    )\n    \n    start = datetime.now()\n    \n    output = pipe(\n        prompt,\n        do_sample=True,\n        max_new_tokens=max_new_tokens, \n        temperature=temperature, \n        top_k=50, \n        top_p=0.95,\n        num_return_sequences=1\n    )\n    \n    stop = datetime.now()\n    \n    totalTimeToPrompt = stop - start\n    print(f\"Execution Time : {totalTimeToPrompt}\")\n    \n    return output","metadata":{"execution":{"iopub.status.busy":"2024-06-11T13:52:40.269532Z","iopub.execute_input":"2024-06-11T13:52:40.270374Z","iopub.status.idle":"2024-06-11T13:52:40.276374Z","shell.execute_reply.started":"2024-06-11T13:52:40.270343Z","shell.execute_reply":"2024-06-11T13:52:40.275375Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"output = generateOutputWithModelPipeline(model, tokenizer, prompt, max_new_tokens=1024)\nprint(output[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2024-06-11T11:44:35.863901Z","iopub.execute_input":"2024-06-11T11:44:35.864981Z","iopub.status.idle":"2024-06-11T11:45:41.876162Z","shell.execute_reply.started":"2024-06-11T11:44:35.864945Z","shell.execute_reply":"2024-06-11T11:45:41.875236Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Execution Time : 0:01:06.005802\n\nWrite a script in Python that implements a circular queue and creates one with user input. Give an example of how the script works and document the code with appropriate comments and docstrings wherever necessary. \nGenerate a response only for the prompt that is given and nothing else. \n\nFor example: \n\n```\nEnter the size of the queue: 3\nQueue is created.\nEnter a command:\na\nEnter the value to be added: 1\n1 is added.\nEnter a command:\na\nEnter the value to be added: 2\n2 is added.\nEnter a command:\na\nEnter the value to be added: 3\n3 is added.\nEnter a command:\na\nEnter the value to be added: 4\nQueue is full.\nEnter a command:\np\n1 is popped.\nEnter a command:\np\n2 is popped.\nEnter a command:\np\n3 is popped.\nEnter a command:\np\nQueue is empty.\nEnter a command:\na\nEnter the value to be added: 4\nQueue is full.\nEnter a command:\na\nEnter the value to be added: 5\nQueue is full.\nEnter a command:\np\nQueue is empty.\nEnter a command:\nq\n\n```\n\nThe queue is implemented as an array and the user input is used to perform the operations of creating the queue, adding an element, popping an element, and quitting the queue. If the user enters a command that is not one of the allowed operations, the script prints an error message and the user is prompted to enter a valid command.\n\nPlease submit a.py file that includes the script and a.txt file that includes the output of the script.\n\n# Solution\n\n```\nclass Queue:\n    def __init__(self, size):\n        self.size = size\n        self.queue = [None] * size\n        self.front = self.rear = -1\n\n    def is_empty(self):\n        return self.front == -1\n\n    def is_full(self):\n        return (self.rear + 1) % self.size == self.front\n\n    def enqueue(self, data):\n        if self.is_full():\n            print(\"Queue is full.\")\n        else:\n            if self.front == -1:\n                self.front = 0\n            self.rear = (self.rear + 1) % self.size\n            self.queue[self.rear] = data\n            print(f\"{data} is added.\")\n\n    def dequeue(self):\n        if self.is_empty():\n            print(\"Queue is empty.\")\n        else:\n            data = self.queue[self.front]\n            self.queue[self.front] = None\n            if self.front == self.rear:\n                self.front = self.rear = -1\n            else:\n                self.front = (self.front + 1) % self.size\n            print(f\"{data} is popped.\")\n\n    def print(self):\n        if self.is_empty():\n            print(\"Queue is empty.\")\n        else:\n            print(\"Queue:\")\n            i = self.front\n            while i!= self.rear:\n                print(self.queue[i], end=\" \")\n                i = (i + 1) % self.size\n            print(self.queue[i])\n\n\ndef main():\n    size = int(input(\"Enter the size of the queue: \"))\n    q = Queue(size)\n    print(\"Queue is created.\")\n    while True:\n        print(\"Enter a command:\")\n        command = input()\n        if command == \"a\":\n            data = int(input(\"Enter the value to be added: \"))\n            q.enqueue(data)\n        elif command == \"p\":\n            q.dequeue()\n        elif command == \"q\":\n            break\n        else:\n            print(\"Invalid command. Try again.\")\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\nThe code creates a Queue class with a constructor and methods for creating the queue, adding an element, popping an element, and printing the queue. It also defines a main function that asks for the size of the queue and creates an instance of the Queue class. The main function contains a while loop that runs until the user enters the \"q\" command. Each command is checked and the appropriate method is called. If the user enters an invalid command, an error message is printed and the user is prompted to enter a valid command.\n\nIn the example output, the user enters the size of the queue as 3, and the queue is created. Then, the user enters the \"a\" command, followed by the value 1, and the 1 is added to the queue. The user enters the \"a\" command again, followed by the value 2, and the 2 is added to the queue. The user enters the \"a\" command again, followed by the value 3, and the 3 is added to the queue. The user ent\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Test Pipeline with Custom Input","metadata":{}},{"cell_type":"code","source":"language = \"Python\"\ncode = \"\"\"\nimport typer\nfrom yaspin import yaspin\n\nfrom utils import *\n\napp = typer.Typer()\nspinner = yaspin()\n\n\n@app.command()\ndef generate(\n    path: str,\n    model: str = typer.Argument(None),\n    outputFile: str = 'output'\n):\n    '''\n    Typer command to generate the documentation for an input script file.\n\n    Arguments:\n    filePath (string) - path to the input file\n    model (string) - string to specify which model to use when generating documentation\n    '''\n\n    if model is None:\n        model = modelUtils.getModelChoice()\n\n    print(f\"Arguments specified:\")\n    print(f\"File Path: {path}\")\n    print(f\"Model: {model}\\n\")\n\n    functions = parserUtils.extractFunctionsAsList(path)\n\n    chain = modelUtils.setupLangChain(model)\n\n    print(\"Generating model outputs...\")\n    # spinner.start()\n\n    modelOutputs = []\n\n    for function in functions:\n        stream = chain.stream({'function': function})\n        outputString = ''\n        \n        for chunk in stream:                \n            # Print each chunk to the terminal\n            print(chunk, end='')\n            # Concatenate each chunk to the output string\n            outputString+= chunk\n        \n        modelOutputs.append(outputString)\n\n    # spinner.stop()\n\n    fileUtils.writeOutputToMarkdownFile(outputFile, modelOutputs, title=f\"Documentation for `{path}`\")\n\n\n@app.command()\ndef easter():\n    '''\n    An easter egg for the keen eyed open-source contributor.\n    '''\n    print(\"This is a test command! If you're here, that means you've discovered something pretty cool in our code-base.\\nCongrats and thanks for using our app!\")\n\n\nif __name__ == \"__main__\":\n    app()\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-06-11T13:52:24.400390Z","iopub.execute_input":"2024-06-11T13:52:24.400695Z","iopub.status.idle":"2024-06-11T13:52:24.406934Z","shell.execute_reply.started":"2024-06-11T13:52:24.400670Z","shell.execute_reply":"2024-06-11T13:52:24.406086Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"template = f\"\"\"\nGiven a script file in {language}, generate its documentation for each function. For each function in the script, document its name, arguments, return values, and a brief explanation of its logic.\n\nStrictly use the following format for each function:\n\n## Function Name: `function_name`\n\n### Arguments\n* `arg1` (type): Description of argument 1.\n* `arg2` (type): Description of argument 2.\n* ...\n\n### Return Values\n* `return_value1` (type): Description of return value 1.\n* `return_value2` (type): Description of return value 2.\n* ...\n\n### Explanation of Function Logic:\n1. Brief explanation of the function logic step by step.\n2. ...\n3. ...\n\nEnsure that code within comments is not parsed and documented. Generate nothing else than what is asked.\n\n{code}\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-06-11T13:52:24.407934Z","iopub.execute_input":"2024-06-11T13:52:24.408193Z","iopub.status.idle":"2024-06-11T13:52:24.424098Z","shell.execute_reply.started":"2024-06-11T13:52:24.408170Z","shell.execute_reply":"2024-06-11T13:52:24.423296Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"template","metadata":{"execution":{"iopub.status.busy":"2024-06-11T13:52:24.425127Z","iopub.execute_input":"2024-06-11T13:52:24.426813Z","iopub.status.idle":"2024-06-11T13:52:24.440192Z","shell.execute_reply.started":"2024-06-11T13:52:24.426788Z","shell.execute_reply":"2024-06-11T13:52:24.439372Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'\\nGiven a script file in Python, generate its documentation for each function. For each function in the script, document its name, arguments, return values, and a brief explanation of its logic.\\n\\nStrictly use the following format for each function:\\n\\n## Function Name: `function_name`\\n\\n### Arguments\\n* `arg1` (type): Description of argument 1.\\n* `arg2` (type): Description of argument 2.\\n* ...\\n\\n### Return Values\\n* `return_value1` (type): Description of return value 1.\\n* `return_value2` (type): Description of return value 2.\\n* ...\\n\\n### Explanation of Function Logic:\\n1. Brief explanation of the function logic step by step.\\n2. ...\\n3. ...\\n\\nEnsure that code within comments is not parsed and documented. Generate nothing else than what is asked.\\n\\n\\nimport typer\\nfrom yaspin import yaspin\\n\\nfrom utils import *\\n\\napp = typer.Typer()\\nspinner = yaspin()\\n\\n\\n@app.command()\\ndef generate(\\n    path: str,\\n    model: str = typer.Argument(None),\\n    outputFile: str = \\'output\\'\\n):\\n    \\'\\'\\'\\n    Typer command to generate the documentation for an input script file.\\n\\n    Arguments:\\n    filePath (string) - path to the input file\\n    model (string) - string to specify which model to use when generating documentation\\n    \\'\\'\\'\\n\\n    if model is None:\\n        model = modelUtils.getModelChoice()\\n\\n    print(f\"Arguments specified:\")\\n    print(f\"File Path: {path}\")\\n    print(f\"Model: {model}\\n\")\\n\\n    functions = parserUtils.extractFunctionsAsList(path)\\n\\n    chain = modelUtils.setupLangChain(model)\\n\\n    print(\"Generating model outputs...\")\\n    # spinner.start()\\n\\n    modelOutputs = []\\n\\n    for function in functions:\\n        stream = chain.stream({\\'function\\': function})\\n        outputString = \\'\\'\\n        \\n        for chunk in stream:                \\n            # Print each chunk to the terminal\\n            print(chunk, end=\\'\\')\\n            # Concatenate each chunk to the output string\\n            outputString+= chunk\\n        \\n        modelOutputs.append(outputString)\\n\\n    # spinner.stop()\\n\\n    fileUtils.writeOutputToMarkdownFile(outputFile, modelOutputs, title=f\"Documentation for `{path}`\")\\n\\n\\n@app.command()\\ndef easter():\\n    \\'\\'\\'\\n    An easter egg for the keen eyed open-source contributor.\\n    \\'\\'\\'\\n    print(\"This is a test command! If you\\'re here, that means you\\'ve discovered something pretty cool in our code-base.\\nCongrats and thanks for using our app!\")\\n\\n\\nif __name__ == \"__main__\":\\n    app()\\n\\n'"},"metadata":{}}]},{"cell_type":"code","source":"output = generateOutputWithModelPipeline(model, tokenizer, template, max_new_tokens=2048)","metadata":{"execution":{"iopub.status.busy":"2024-06-11T13:52:46.722918Z","iopub.execute_input":"2024-06-11T13:52:46.723285Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(output[0][\"generated_text\"])","metadata":{"execution":{"iopub.status.busy":"2024-06-11T13:52:25.132912Z","iopub.status.idle":"2024-06-11T13:52:25.133262Z","shell.execute_reply.started":"2024-06-11T13:52:25.133095Z","shell.execute_reply":"2024-06-11T13:52:25.133109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}